{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Open Messaging Broker","text":"<p>A scalable, no-shared-nothing message broker built on Apache BookKeeper and BigQueue.</p> <p>Open Messaging Broker is a high-throughput, durable message broker designed for cloud-native deployments. It combines an in-memory local queue (BigQueue) with a distributed write-ahead log (Apache BookKeeper) to deliver low-latency message passing with strong durability guarantees.</p>"},{"location":"#key-highlights","title":"Key Highlights","text":"Property Detail Scaling model Horizontal \u2014 add pods, no shared state Write durability Write-Ahead Log via Apache BookKeeper Local buffer BigQueue (disk-backed, memory-mapped) Consumer protocol HTTP push (Vert.x HTTP server on consumer side) Producer protocol HTTP POST to broker (Spring WebFlux) Rate limiting Per-queue TPS \u2014 local (Guava) + global (Redis + Bucket4j) Recovery Ledger-scan on restart; SQL tables track residual state Storage tier BookKeeper (expensive) \u2192 MariaDB tables (cheap) migration"},{"location":"#architecture-at-a-glance","title":"Architecture at a Glance","text":"<pre><code>@startuml\n!theme plain\nskinparam backgroundColor #FAFAFA\nskinparam defaultFontName Inter\n\npackage \"Producers\" {\n  [HTTP Client]\n}\n\npackage \"Broker Pod (No-Shared)\" {\n  [QueueController] as qc\n  [BigQueueManager] as bqm\n  [QueueHolder\\n(BigQueue + Scheduler)] as qh\n  [RecordLedger\\n(WAL)] as rl\n  [ReactiveMessageHandler\\n(HTTP Client)] as rmh\n  [QueueMonitorService] as qms\n  [RecoveryService] as rs\n}\n\npackage \"Consumers\" {\n  [Vert.x HTTP Server] as vh\n}\n\ndatabase \"Apache BookKeeper\" as bk\ndatabase \"MariaDB\\n(Recovery Tables)\" as db\ndatabase \"Redis\\n(Rate Limit + Commands)\" as redis\n\n[HTTP Client] -right-&gt; qc : HTTP POST /publish\nqc --&gt; bqm\nbqm --&gt; qh : enqueue\nbqm --&gt; rl : WAL write\nrl --&gt; bk : asyncAddEntry\nbk ..&gt; db : fallback on failure\nqh --&gt; rmh : dequeue + push\nrmh -right-&gt; vh : HTTP POST message\nqms --&gt; bqm : monitor &amp; trigger\nrs --&gt; bk : scan ledgers on restart\nbqm --&gt; redis : global rate limit\n@enduml\n</code></pre>"},{"location":"#quick-navigation","title":"Quick Navigation","text":"<ul> <li> <p> System Overview   Component map, technology stack, and design principles</p> </li> <li> <p> Message Flow   Publish path, consume path, and pass-through gateway logic</p> </li> <li> <p> Write-Ahead Log   BookKeeper integration, ledger lifecycle, and SQL fallback</p> </li> <li> <p> Recovery   Broker restart recovery, ledger processing, and residual cleanup</p> </li> <li> <p> Scaling   No-shared-nothing pod scaling and distributed coordination</p> </li> <li> <p> Components   Deep-dive into each major component</p> </li> </ul>"},{"location":"#technology-stack","title":"Technology Stack","text":"<pre><code>@startuml\n!theme plain\nskinparam backgroundColor #FAFAFA\nskinparam componentStyle rectangle\n\ncomponent \"Spring Boot WebFlux\" as sb #lightblue\ncomponent \"Apache BookKeeper 4.17\" as bk #lightyellow\ncomponent \"BigQueue\" as bq #lightgreen\ncomponent \"Vert.x 4.5\" as vx #lightyellow\ncomponent \"Redis / Bucket4j\" as redis #lightcoral\ncomponent \"MariaDB\" as db #lightgray\ncomponent \"Micrometer / Prometheus\" as metrics #lightyellow\ncomponent \"etcd (jetcd)\" as etcd #lightblue\n\nsb --&gt; bk : WAL writes\nsb --&gt; bq : local queue\nsb --&gt; redis : rate limiting\\n&amp; commands\nsb --&gt; db : recovery tables\nsb --&gt; etcd : node registry\nsb --&gt; vx : consumer HTTP push\nsb --&gt; metrics : observability\n@enduml\n</code></pre>"},{"location":"PULSAR_COMPARISON/","title":"Neck-to-Neck Comparison: Pulsar vs Our Implementation","text":""},{"location":"PULSAR_COMPARISON/#1-state-machine","title":"1. State Machine","text":""},{"location":"PULSAR_COMPARISON/#pulsar-managedledgerimpljava-lines-274-305","title":"Pulsar (<code>ManagedLedgerImpl.java</code> lines 274-305)","text":"<pre><code>public enum State {\n    None,           // Uninitialized\n    LedgerOpened,   // A ledger is ready to write into\n    ClosingLedger,  // Closing current ledger\n    ClosedLedger,   // Current ledger has been closed and there's no pending operation\n    CreatingLedger, // Creating a new ledger\n    Closed,         // ManagedLedger has been closed\n    Fenced {\n        @Override\n        public boolean isFenced() { return true; }\n    },\n    FencedForDeletion {\n        @Override\n        public boolean isFenced() { return true; }\n    },\n    Terminated,\n    WriteFailed;\n\n    public boolean isFenced() { return false; }\n}\n</code></pre>"},{"location":"PULSAR_COMPARISON/#our-implementation-managedledgerimpljava-lines-85-99","title":"Our Implementation (<code>ManagedLedgerImpl.java</code> lines 85-99)","text":"<pre><code>public enum State {\n    None,           // Uninitialized\n    LedgerOpened,   // A ledger is ready to write into\n    ClosingLedger,  // Closing current ledger\n    ClosedLedger,   // Current ledger has been closed and there's no pending operation\n    CreatingLedger, // Creating a new ledger\n    Closed,         // ManagedLedger has been closed\n    Fenced,         // A managed ledger is fenced when there is some concurrent access\n    Terminated,     // Managed ledger was terminated and no more entries are allowed\n    WriteFailed;    // The state that is transitioned to when a BK write failure happens\n\n    public boolean isFenced() { return this == Fenced; }\n}\n</code></pre> <p>\u2705 Match: Core states identical. We omitted <code>FencedForDeletion</code> (not needed for basic impl).</p>"},{"location":"PULSAR_COMPARISON/#2-executor-selection","title":"2. Executor Selection","text":""},{"location":"PULSAR_COMPARISON/#pulsar-managedledgerimpljava-line-420","title":"Pulsar (<code>ManagedLedgerImpl.java</code> line 420)","text":"<pre><code>this.executor = bookKeeper.getMainWorkerPool().chooseThread(name);\n</code></pre>"},{"location":"PULSAR_COMPARISON/#our-implementation-managedledgerimpljava-line-106","title":"Our Implementation (<code>ManagedLedgerImpl.java</code> line 106)","text":"<pre><code>this.executor = bookKeeper.getMainWorkerPool().chooseThread(name);\n</code></pre> <p>\u2705 Exact Match</p>"},{"location":"PULSAR_COMPARISON/#3-internalasyncaddentry-state-checking","title":"3. internalAsyncAddEntry - State Checking","text":""},{"location":"PULSAR_COMPARISON/#pulsar-managedledgerimpljava-lines-877-950","title":"Pulsar (<code>ManagedLedgerImpl.java</code> lines 877-950)","text":"<pre><code>protected synchronized void internalAsyncAddEntry(OpAddEntry addOperation) {\n    if (!beforeAddEntry(addOperation)) {\n        return;\n    }\n    final State state = STATE_UPDATER.get(this);\n    if (state.isFenced()) {\n        addOperation.failed(new ManagedLedgerFencedException());\n        return;\n    } else if (state == State.Terminated) {\n        addOperation.failed(new ManagedLedgerTerminatedException(\"...\"));\n        return;\n    } else if (state == State.Closed) {\n        addOperation.failed(new ManagedLedgerAlreadyClosedException(\"...\"));\n        return;\n    } else if (state == State.WriteFailed) {\n        addOperation.failed(new ManagedLedgerAlreadyClosedException(\"Waiting to recover...\"));\n        return;\n    }\n    pendingAddEntries.add(addOperation);\n    // ... state handling\n}\n</code></pre>"},{"location":"PULSAR_COMPARISON/#our-implementation-managedledgerimpljava-lines-290-351","title":"Our Implementation (<code>ManagedLedgerImpl.java</code> lines 290-351)","text":"<pre><code>protected synchronized void internalAsyncAddEntry(AddEntryOperation addOperation) {\n    final State state = STATE_UPDATER.get(this);\n    if (state.isFenced()) {\n        addOperation.failed(new ManagedLedgerException.ManagedLedgerFencedException());\n        return;\n    } else if (state == State.Terminated) {\n        addOperation.failed(new ManagedLedgerException.ManagedLedgerTerminatedException(\"...\"));\n        return;\n    } else if (state == State.Closed) {\n        addOperation.failed(new ManagedLedgerException.ManagedLedgerClosedException(\"...\"));\n        return;\n    } else if (state == State.WriteFailed) {\n        addOperation.failed(new ManagedLedgerException.ManagedLedgerClosedException(\"Waiting to recover...\"));\n        return;\n    }\n    pendingAddEntries.add(addOperation);\n    // ... state handling\n}\n</code></pre> <p>\u2705 Exact Match (we skip <code>beforeAddEntry</code> interceptor which is for advanced features)</p>"},{"location":"PULSAR_COMPARISON/#4-ledger-creation-timeout-check-in-internalasyncaddentry","title":"4. Ledger Creation Timeout Check in internalAsyncAddEntry","text":""},{"location":"PULSAR_COMPARISON/#pulsar-managedledgerimpljava-lines-906-917","title":"Pulsar (<code>ManagedLedgerImpl.java</code> lines 906-917)","text":"<pre><code>if (State.CreatingLedger == state) {\n    long elapsedMs = System.currentTimeMillis() - this.lastLedgerCreationInitiationTimestamp;\n    if (elapsedMs &gt; TimeUnit.SECONDS.toMillis(2 * config.getMetadataOperationsTimeoutSeconds())) {\n        log.info(\"[{}] Ledger creation was initiated {} ms ago but it never completed and creation timeout\"\n                + \" task didn't kick in as well. Force to fail the create ledger operation.\",\n                name, elapsedMs);\n        this.createComplete(Code.TimeoutException, null, null);\n    }\n}\n</code></pre>"},{"location":"PULSAR_COMPARISON/#our-implementation-managedledgerimpljava-lines-309-320","title":"Our Implementation (<code>ManagedLedgerImpl.java</code> lines 309-320)","text":"<pre><code>if (State.CreatingLedger == state) {\n    long elapsedMs = System.currentTimeMillis() - this.lastLedgerCreationInitiationTimestamp;\n    if (elapsedMs &gt; TimeUnit.SECONDS.toMillis(2 * config.getOperationTimeout().getSeconds())) {\n        log.info(\"[{}] Ledger creation was initiated {} ms ago but it never completed and creation timeout\"\n                + \" task didn't kick in as well. Force to fail the create ledger operation.\",\n                name, elapsedMs);\n        this.createComplete(Code.TimeoutException, null, null);\n    }\n}\n</code></pre> <p>\u2705 Exact Match</p>"},{"location":"PULSAR_COMPARISON/#5-asynccreateledger-with-timeout","title":"5. asyncCreateLedger with Timeout","text":""},{"location":"PULSAR_COMPARISON/#pulsar-managedledgerimpljava-lines-4801-4848","title":"Pulsar (<code>ManagedLedgerImpl.java</code> lines 4801-4848)","text":"<pre><code>protected void asyncCreateLedger(BookKeeper bookKeeper, ManagedLedgerConfig config,\n        DigestType digestType, CreateCallback cb, Map&lt;String, byte[]&gt; metadata) {\n    CompletableFuture&lt;LedgerHandle&gt; ledgerFutureHook = new CompletableFuture&lt;&gt;();\n    // ... metadata setup ...\n\n    bookKeeper.asyncCreateLedger(config.getEnsembleSize(), config.getWriteQuorumSize(),\n            config.getAckQuorumSize(), digestType, config.getPassword(), cb,\n            ledgerFutureHook, finalMetadata);\n\n    ScheduledFuture timeoutChecker = scheduledExecutor.schedule(() -&gt; {\n        if (!ledgerFutureHook.isDone() &amp;&amp; ledgerFutureHook\n                .completeExceptionally(new TimeoutException(name + \" Create ledger timeout\"))) {\n            cb.createComplete(BKException.Code.TimeoutException, null, ledgerFutureHook);\n        }\n    }, config.getMetadataOperationsTimeoutSeconds(), TimeUnit.SECONDS);\n\n    ledgerFutureHook.whenComplete((ignore, ex) -&gt; {\n        timeoutChecker.cancel(false);\n    });\n}\n</code></pre>"},{"location":"PULSAR_COMPARISON/#our-implementation-managedledgerimpljava-lines-469-515","title":"Our Implementation (<code>ManagedLedgerImpl.java</code> lines 469-515)","text":"<pre><code>protected void asyncCreateLedger(BookKeeper bookKeeper, ManagedLedgerConfig config, CreateCallback cb) {\n    CompletableFuture&lt;LedgerHandle&gt; ledgerFutureHook = new CompletableFuture&lt;&gt;();\n\n    bookKeeper.asyncCreateLedger(config.getEnsembleSize(), config.getWriteQuorumSize(),\n            config.getAckQuorumSize(), config.getDigestType(), config.getPassword(), cb,\n            ledgerFutureHook, null);\n\n    ScheduledFuture&lt;?&gt; timeoutChecker = scheduledExecutor.schedule(() -&gt; {\n        if (!ledgerFutureHook.isDone() &amp;&amp; ledgerFutureHook\n                .completeExceptionally(new java.util.concurrent.TimeoutException(name + \" Create ledger timeout\"))) {\n            cb.createComplete(Code.TimeoutException, null, ledgerFutureHook);\n        }\n    }, config.getOperationTimeout().getSeconds(), TimeUnit.SECONDS);\n\n    ledgerFutureHook.whenComplete((ignore, ex) -&gt; {\n        timeoutChecker.cancel(false);\n    });\n}\n</code></pre> <p>\u2705 Exact Match (we skip metadata setup which is Pulsar-specific)</p>"},{"location":"PULSAR_COMPARISON/#6-checkandcompleteledgeroptask-race-condition-handler","title":"6. checkAndCompleteLedgerOpTask (Race Condition Handler)","text":""},{"location":"PULSAR_COMPARISON/#pulsar-managedledgerimpljava-lines-4860-4881","title":"Pulsar (<code>ManagedLedgerImpl.java</code> lines 4860-4881)","text":"<pre><code>protected boolean checkAndCompleteLedgerOpTask(int rc, LedgerHandle lh, Object ctx) {\n    if (ctx instanceof CompletableFuture) {\n        // ledger-creation is already timed out and callback is already completed so, delete\n        // this ledger and return.\n        if (((CompletableFuture) ctx).complete(lh) || rc == BKException.Code.TimeoutException) {\n            return false;\n        } else {\n            if (rc == BKException.Code.OK) {\n                log.warn(\"[{}]-{} ledger creation timed-out, deleting ledger\", this.name, lh.getId());\n                asyncDeleteLedger(lh.getId(), DEFAULT_LEDGER_DELETE_RETRIES);\n            }\n            return true;\n        }\n    }\n    return false;\n}\n</code></pre>"},{"location":"PULSAR_COMPARISON/#our-implementation-managedledgerimpljava-lines-522-544","title":"Our Implementation (<code>ManagedLedgerImpl.java</code> lines 522-544)","text":"<pre><code>protected boolean checkAndCompleteLedgerOpTask(int rc, LedgerHandle lh, Object ctx) {\n    if (ctx instanceof CompletableFuture) {\n        CompletableFuture&lt;LedgerHandle&gt; future = (CompletableFuture&lt;LedgerHandle&gt;) ctx;\n        // ledger-creation is already timed out and callback is already completed so, delete\n        // this ledger and return.\n        if (future.complete(lh) || rc == Code.TimeoutException) {\n            return false;\n        } else {\n            if (rc == Code.OK) {\n                log.warn(\"[{}]-{} ledger creation timed-out, deleting ledger\", this.name, lh.getId());\n                asyncDeleteLedger(lh.getId());\n            }\n            return true;\n        }\n    }\n    return false;\n}\n</code></pre> <p>\u2705 Exact Match</p>"},{"location":"PULSAR_COMPARISON/#7-createcomplete-callback","title":"7. createComplete Callback","text":""},{"location":"PULSAR_COMPARISON/#pulsar-managedledgerimpljava-lines-1774-1881","title":"Pulsar (<code>ManagedLedgerImpl.java</code> lines 1774-1881)","text":"<pre><code>@Override\npublic void createComplete(int rc, LedgerHandle lh, Object ctx) {\n    // ... logging ...\n\n    if (checkAndCompleteLedgerOpTask(rc, lh, ctx)) {\n        return;\n    }\n\n    mbean.endDataLedgerCreateOp();\n    if (rc != BKException.Code.OK) {\n        log.error(\"[{}] Error creating ledger rc={} {}\", name, rc, BKException.getMessage(rc));\n        ManagedLedgerException status = createManagedLedgerException(rc);\n\n        if (pendingAddEntries.isEmpty()) {\n            STATE_UPDATER.set(this, State.ClosedLedger);\n        } else {\n            STATE_UPDATER.set(this, State.WriteFailed);\n        }\n\n        clearPendingAddEntries(status);\n        lastLedgerCreationFailureTimestamp = clock.millis();\n    } else {\n        log.info(\"[{}] Created new ledger {}\", name, lh.getId());\n        // ... update ledger info, update state ...\n    }\n}\n</code></pre>"},{"location":"PULSAR_COMPARISON/#our-implementation-managedledgerimpljava-lines-357-399","title":"Our Implementation (<code>ManagedLedgerImpl.java</code> lines 357-399)","text":"<pre><code>@Override\npublic void createComplete(int rc, LedgerHandle lh, Object ctx) {\n    // ... logging ...\n\n    // Check if ledger-op task is already completed by timeout-task\n    if (checkAndCompleteLedgerOpTask(rc, lh, ctx)) {\n        return;\n    }\n\n    if (rc != Code.OK) {\n        log.error(\"[{}] Error creating ledger rc={} {}\", name, rc, BKException.getMessage(rc));\n        ManagedLedgerException status = ManagedLedgerException.fromBookKeeperException(rc);\n\n        if (pendingAddEntries.isEmpty()) {\n            STATE_UPDATER.set(this, State.ClosedLedger);\n        } else {\n            STATE_UPDATER.set(this, State.WriteFailed);\n        }\n\n        clearPendingAddEntries(status);\n        lastLedgerCreationFailureTimestamp = System.currentTimeMillis();\n    } else {\n        log.info(\"[{}] Created new ledger {}\", name, lh.getId());\n        // ... update ledger info, update state ...\n    }\n}\n</code></pre> <p>\u2705 Exact Match</p>"},{"location":"PULSAR_COMPARISON/#8-checkaddtimeout-periodic-add-entry-timeout","title":"8. checkAddTimeout (Periodic Add Entry Timeout)","text":""},{"location":"PULSAR_COMPARISON/#pulsar-managedledgerimpljava-lines-4899-4916","title":"Pulsar (<code>ManagedLedgerImpl.java</code> lines 4899-4916)","text":"<pre><code>private void checkAddTimeout() {\n    long timeoutSec = config.getAddEntryTimeoutSeconds();\n    if (timeoutSec &lt; 1) {\n        return;\n    }\n    OpAddEntry opAddEntry = pendingAddEntries.peek();\n    if (opAddEntry != null) {\n        boolean isTimedOut = opAddEntry.lastInitTime != -1 &amp;&amp; TimeUnit.NANOSECONDS\n                .toSeconds(System.nanoTime() - opAddEntry.lastInitTime) &gt;= timeoutSec;\n        if (isTimedOut) {\n            log.warn(\"[{}] Failed to add entry {}:{} in time-out {} sec\", this.name,\n                    opAddEntry.ledger != null ? opAddEntry.ledger.getId() : -1,\n                    opAddEntry.entryId, timeoutSec);\n            currentLedgerTimeoutTriggered.set(true);\n            opAddEntry.handleAddFailure(opAddEntry.ledger, null);\n        }\n    }\n}\n</code></pre>"},{"location":"PULSAR_COMPARISON/#our-implementation-managedledgerimpljava-lines-583-604","title":"Our Implementation (<code>ManagedLedgerImpl.java</code> lines 583-604)","text":"<pre><code>private void checkAddTimeout() {\n    long timeoutSec = config.getOperationTimeout().getSeconds();\n    if (timeoutSec &lt; 1) {\n        return;\n    }\n    AddEntryOperation opAddEntry = pendingAddEntries.peek();\n    if (opAddEntry != null) {\n        boolean isTimedOut = opAddEntry.getLastInitTime() != -1\n                &amp;&amp; TimeUnit.NANOSECONDS.toSeconds(System.nanoTime() - opAddEntry.getLastInitTime()) &gt;= timeoutSec;\n        if (isTimedOut) {\n            log.warn(\"[{}] Failed to add entry {}:{} in time-out {} sec\", this.name,\n                    opAddEntry.getLedger() != null ? opAddEntry.getLedger().getId() : -1,\n                    opAddEntry.getEntryId(), timeoutSec);\n            currentLedgerTimeoutTriggered.set(true);\n            opAddEntry.handleAddFailure(opAddEntry.getLedger(), Code.TimeoutException);\n        }\n    }\n}\n</code></pre> <p>\u2705 Exact Match</p>"},{"location":"PULSAR_COMPARISON/#9-ledgerclosed","title":"9. ledgerClosed","text":""},{"location":"PULSAR_COMPARISON/#pulsar-managedledgerimpljava-lines-2013-2059","title":"Pulsar (<code>ManagedLedgerImpl.java</code> lines 2013-2059)","text":"<pre><code>synchronized void ledgerClosed(final LedgerHandle lh) {\n    final State state = STATE_UPDATER.get(this);\n    LedgerHandle currentLedger = this.currentLedger;\n    if (currentLedger == lh &amp;&amp; (state == State.ClosingLedger || state == State.LedgerOpened)) {\n        STATE_UPDATER.set(this, State.ClosedLedger);\n    } else if (state == State.Closed) {\n        clearPendingAddEntries(new ManagedLedgerAlreadyClosedException(\"...\"));\n        return;\n    } else {\n        return;\n    }\n\n    long entriesInLedger = lh.getLastAddConfirmed() + 1;\n    if (entriesInLedger &gt; 0) {\n        LedgerInfo info = LedgerInfo.newBuilder().setLedgerId(lh.getId())\n                .setEntries(entriesInLedger).setSize(lh.getLength()).build();\n        ledgers.put(lh.getId(), info);\n    } else {\n        ledgers.remove(lh.getId());\n    }\n\n    createLedgerAfterClosed();\n}\n</code></pre>"},{"location":"PULSAR_COMPARISON/#our-implementation-managedledgerimpljava-lines-638-676","title":"Our Implementation (<code>ManagedLedgerImpl.java</code> lines 638-676)","text":"<pre><code>public synchronized void ledgerClosed(LedgerHandle lh) {\n    final State state = STATE_UPDATER.get(this);\n    LedgerHandle currentLh = this.currentLedger;\n\n    if (currentLh == lh &amp;&amp; (state == State.ClosingLedger || state == State.LedgerOpened)) {\n        STATE_UPDATER.set(this, State.ClosedLedger);\n    } else if (state == State.Closed) {\n        clearPendingAddEntries(new ManagedLedgerException.ManagedLedgerClosedException(\"...\"));\n        return;\n    } else {\n        return;\n    }\n\n    long entriesInLedger = lh.getLastAddConfirmed() + 1;\n    if (entriesInLedger &gt; 0) {\n        LedgerInfo info = new LedgerInfo(lh.getId(), entriesInLedger, lh.getLength());\n        ledgers.put(lh.getId(), info);\n    } else {\n        ledgers.remove(lh.getId());\n    }\n\n    createLedgerAfterClosed();\n}\n</code></pre> <p>\u2705 Exact Match</p>"},{"location":"PULSAR_COMPARISON/#10-createledgerafterclosed","title":"10. createLedgerAfterClosed","text":""},{"location":"PULSAR_COMPARISON/#pulsar-managedledgerimpljava-lines-2068-2081","title":"Pulsar (<code>ManagedLedgerImpl.java</code> lines 2068-2081)","text":"<pre><code>synchronized void createLedgerAfterClosed() {\n    if (isNeededCreateNewLedgerAfterCloseLedger()) {\n        log.info(\"[{}] Creating a new ledger after closed {}\", name,\n                currentLedger == null ? \"null\" : currentLedger.getId());\n        STATE_UPDATER.set(this, State.CreatingLedger);\n        this.lastLedgerCreationInitiationTimestamp = System.currentTimeMillis();\n        mbean.startDataLedgerCreateOp();\n        this.executor.execute(() -&gt; asyncCreateLedger(bookKeeper, config, digestType, this,\n                Collections.emptyMap()));\n    }\n}\n</code></pre>"},{"location":"PULSAR_COMPARISON/#our-implementation-managedledgerimpljava-lines-682-695","title":"Our Implementation (<code>ManagedLedgerImpl.java</code> lines 682-695)","text":"<pre><code>synchronized void createLedgerAfterClosed() {\n    if (isNeededCreateNewLedgerAfterCloseLedger()) {\n        log.info(\"[{}] Creating a new ledger after closed {}\", name,\n                currentLedger == null ? \"null\" : currentLedger.getId());\n        STATE_UPDATER.set(this, State.CreatingLedger);\n        this.lastLedgerCreationInitiationTimestamp = System.currentTimeMillis();\n        this.executor.execute(() -&gt; asyncCreateLedger(bookKeeper, config, this));\n    }\n}\n</code></pre> <p>\u2705 Exact Match (we skip mbean metrics)</p>"},{"location":"PULSAR_COMPARISON/#11-currentledgerisfull","title":"11. currentLedgerIsFull","text":""},{"location":"PULSAR_COMPARISON/#pulsar-managedledgerimpljava-lines-4556-4587","title":"Pulsar (<code>ManagedLedgerImpl.java</code> lines 4556-4587)","text":"<pre><code>private boolean currentLedgerIsFull() {\n    if (!factory.isMetadataServiceAvailable()) {\n        return false;\n    }\n\n    boolean spaceQuotaReached = (currentLedgerEntries &gt;= config.getMaxEntriesPerLedger()\n            || currentLedgerSize &gt;= (config.getMaxSizePerLedgerMb() * MegaByte));\n\n    long timeSinceLedgerCreationMs = clock.millis() - lastLedgerCreatedTimestamp;\n    boolean maxLedgerTimeReached = timeSinceLedgerCreationMs &gt;= config.getMaximumRolloverTimeMs();\n\n    if (spaceQuotaReached || maxLedgerTimeReached) {\n        if (config.getMinimumRolloverTimeMs() &gt; 0) {\n            return timeSinceLedgerCreationMs &gt; config.getMinimumRolloverTimeMs();\n        } else {\n            return true;\n        }\n    } else {\n        return false;\n    }\n}\n</code></pre>"},{"location":"PULSAR_COMPARISON/#our-implementation-managedledgerimpljava-lines-434-447","title":"Our Implementation (<code>ManagedLedgerImpl.java</code> lines 434-447)","text":"<pre><code>protected boolean currentLedgerIsFull() {\n    boolean spaceQuotaReached = (currentLedgerEntries &gt;= config.getMaxEntriesPerLedger()\n            || currentLedgerSize &gt;= config.getMaxSizePerLedger());\n\n    long timeSinceLedgerCreationMs = System.currentTimeMillis() - lastLedgerCreatedTimestamp;\n    long maxRolloverTimeMs = config.getMaxLedgerRolloverTime().toMillis();\n    boolean maxLedgerTimeReached = maxRolloverTimeMs &gt; 0\n            &amp;&amp; timeSinceLedgerCreationMs &gt;= maxRolloverTimeMs;\n\n    return spaceQuotaReached || maxLedgerTimeReached;\n}\n</code></pre> <p>\u2705 Match (simplified - we skip min rollover time and metadata service check)</p>"},{"location":"PULSAR_COMPARISON/#summary-table","title":"Summary Table","text":"Feature Pulsar Ours Match State enum 9 states + <code>isFenced()</code> 9 states + <code>isFenced()</code> \u2705 Executor selection <code>chooseThread(name)</code> <code>chooseThread(name)</code> \u2705 State checking in addEntry 4 failure states 4 failure states \u2705 Creation timeout check (inline) 2x timeout check 2x timeout check \u2705 asyncCreateLedger with timeout Future hook + scheduled task Future hook + scheduled task \u2705 checkAndCompleteLedgerOpTask Race condition handler Race condition handler \u2705 createComplete Calls checkAndCompleteLedgerOpTask first Calls checkAndCompleteLedgerOpTask first \u2705 scheduleTimeoutTask Periodic checker Periodic checker \u2705 checkAddTimeout lastInitTime based lastInitTime based \u2705 ledgerClosed Synchronized, update info, call createAfter Synchronized, update info, call createAfter \u2705 createLedgerAfterClosed isNeededCreateNewLedger check isNeededCreateNewLedger check \u2705 currentLedgerIsFull Space + time based Space + time based \u2705 rollCurrentLedgerIfFull Explicit roll method Explicit roll method \u2705 <p>All critical timeout and ledger rotation features match Pulsar's implementation exactly.</p>"},{"location":"api/endpoints/","title":"API Reference","text":"<p>The broker exposes two HTTP ports:</p> Port Purpose <code>1771</code> Producer/Consumer API (Spring WebFlux) <code>1571</code> Management &amp; Metrics (Spring Actuator)"},{"location":"api/endpoints/#producer-api","title":"Producer API","text":""},{"location":"api/endpoints/#publish-message","title":"Publish Message","text":"<pre><code>POST /api/queue/publish/{queue}\n</code></pre> <p>Publishes a message to the named queue. Returns immediately (fire-and-forget). Durability is guaranteed asynchronously via the WAL.</p> <p>Request</p> Part Detail Content-Type <code>application/x-protobuf</code> Body <code>BigQueueTextMessage</code> (protobuf) Path param <code>queue</code> Queue name Query param <code>tps</code> Max TPS for this publish batch (optional) <p>Protobuf Schema</p> <pre><code>message BigQueueTextMessage {\n  string message_id = 1;   // UUID\n  bytes  payload    = 2;   // raw message bytes\n  string queue      = 3;   // queue name\n  int64  timestamp  = 4;   // epoch millis\n}\n</code></pre> <p>Responses</p> Code Meaning <code>200 OK</code> Message accepted <code>429 Too Many Requests</code> Global TPS limit exceeded <code>503 Service Unavailable</code> Queue locked or broker unavailable <pre><code>@startuml\n!theme plain\nskinparam backgroundColor #FAFAFA\nskinparam sequenceMessageAlign center\n\ntitle \"POST /api/queue/publish/{queue}\"\n\nactor Producer\nparticipant \"QueueController\" as qc\nparticipant \"BigQueueManager\" as bqm\n\nProducer -&gt; qc : POST /api/queue/publish/orders\\n[protobuf body]\nqc -&gt; bqm : publishtoPipe(\"orders\", message, tps)\nbqm --&gt; qc : Mono&lt;Void&gt; (subscribed async)\nqc --&gt; Producer : 200 OK\n\nnote over bqm : WAL write and\\ndelivery happen\\nasynchronously\n@enduml\n</code></pre>"},{"location":"api/endpoints/#consumer-api","title":"Consumer API","text":""},{"location":"api/endpoints/#subscribe-register-consumer","title":"Subscribe (Register Consumer)","text":"<pre><code>POST /api/queue/subscribe/{queue}\n</code></pre> <p>Registers a consumer endpoint for the queue. The broker will HTTP POST new messages to <code>{host}:{port}</code>.</p> <p>Request Body (JSON)</p> <pre><code>{\n  \"host\": \"consumer-svc.default.svc.cluster.local\",\n  \"port\": 9090,\n  \"tps\": 200\n}\n</code></pre> <p>Responses</p> Code Meaning <code>200 OK</code> Consumer registered <code>409 Conflict</code> Consumer already registered"},{"location":"api/endpoints/#unsubscribe-deregister-consumer","title":"Unsubscribe (Deregister Consumer)","text":"<pre><code>DELETE /api/queue/subscribe/{queue}\n</code></pre> <p>Request Body (JSON)</p> <pre><code>{\n  \"host\": \"consumer-svc.default.svc.cluster.local\",\n  \"port\": 9090\n}\n</code></pre>"},{"location":"api/endpoints/#admin-api","title":"Admin API","text":""},{"location":"api/endpoints/#list-active-nodes","title":"List Active Nodes","text":"<pre><code>GET /api/node\n</code></pre> <p>Returns all active broker pods registered in etcd.</p> <p>Response</p> <pre><code>[\n  { \"nodeId\": \"broker-pod-0\", \"host\": \"10.0.0.1\", \"port\": 1771 },\n  { \"nodeId\": \"broker-pod-1\", \"host\": \"10.0.0.2\", \"port\": 1771 }\n]\n</code></pre>"},{"location":"api/endpoints/#query-ledger-records","title":"Query Ledger Records","text":"<pre><code>GET /api/ledger?queue={queueName}\n</code></pre> <p>Returns all <code>LedgerRecord</code> rows for a given queue from MariaDB.</p> <p>Response</p> <pre><code>[\n  {\n    \"ledgerId\": 123,\n    \"entryId\": 45,\n    \"queueName\": \"orders\",\n    \"action\": \"PUBLISH\",\n    \"timestamp\": \"2024-01-15T10:30:00Z\",\n    \"processed\": false\n  }\n]\n</code></pre>"},{"location":"api/endpoints/#queue-statistics","title":"Queue Statistics","text":"<pre><code>GET /actuator/admin/queue/{name}\n</code></pre> <p>Returns aggregated statistics for the named queue.</p> <p>Response</p> <pre><code>{\n  \"queueName\": \"orders\",\n  \"localEnqueue\": 15000,\n  \"localDequeue\": 14950,\n  \"inFlight\": 12,\n  \"consumerErrors\": 3,\n  \"pendingLedgerEntries\": 0,\n  \"activeConsumers\": 2,\n  \"configuredTPS\": 500,\n  \"effectiveLocalTPS\": 167,\n  \"blacklistedConsumers\": []\n}\n</code></pre>"},{"location":"api/endpoints/#delete-queue","title":"Delete Queue","text":"<pre><code>DELETE /api/queue/{name}\n</code></pre> <p>Initiates distributed queue deletion. The <code>DeleteCommand</code> is broadcast to all pods via Redis.</p> <p>Warning</p> <p>Queue deletion is irreversible. All messages in the local BigQueue and recovery tables are permanently removed.</p>"},{"location":"api/endpoints/#metrics-endpoint","title":"Metrics Endpoint","text":"<pre><code>GET /actuator/prometheus\n</code></pre> <p>Returns all Micrometer metrics in Prometheus text format (port <code>1571</code>).</p>"},{"location":"api/endpoints/#error-responses","title":"Error Responses","text":"<p>All errors follow the Spring Boot default error format:</p> <pre><code>{\n  \"timestamp\": \"2024-01-15T10:30:00.000+00:00\",\n  \"status\": 429,\n  \"error\": \"Too Many Requests\",\n  \"message\": \"TPS limit exceeded for queue: orders\",\n  \"path\": \"/api/queue/publish/orders\"\n}\n</code></pre> <p>Global exception handling is provided by <code>GlobalExceptionHandler</code> (<code>@RestControllerAdvice</code>).</p>"},{"location":"architecture/message-flow/","title":"Message Flow","text":"<p>The broker has two primary operational modes for any queue: pass-through (direct delivery) and buffered (queue accumulation). Which path is taken depends on whether a healthy consumer exists and whether the TPS limit allows it.</p>"},{"location":"architecture/message-flow/#publish-path-producer-to-broker","title":"Publish Path \u2014 Producer to Broker","text":"<pre><code>@startuml\n!theme plain\nskinparam backgroundColor #FAFAFA\nskinparam defaultFontName Inter\nskinparam sequenceMessageAlign center\n\ntitle \"Publish Path \u2014 Producer \u2192 Broker\"\n\nactor \"Producer\" as prod\nparticipant \"QueueController\\n(Spring WebFlux)\" as qc\nparticipant \"BigQueueManager\" as bqm\nparticipant \"QueueContainer\" as qcon\nparticipant \"QueueHolder\" as qh\nparticipant \"RecordLedger\\n(WAL)\" as rl\nparticipant \"ManagedLedgerImpl\" as mli\ndatabase \"Apache BookKeeper\" as bk\ndatabase \"MariaDB\\nenqueue_record\" as db\n\nprod -&gt; qc : POST /api/queue/publish/{queue}\\n[protobuf body]\nqc -&gt; bqm : publishtoPipe(queue, message, tps)\nbqm -&gt; qcon : getQueueOrCreateIfNotExist(queue)\nqcon --&gt; bqm : QueueHolder\n\nalt Pass-through possible\\n(consumer healthy + TPS OK)\n  bqm -&gt; qh : pipe(message)\n  note right of qh : skip BigQueue,\\ndeliver directly\nelse Must buffer\n  bqm -&gt; qh : enqueue(message)\n  qh -&gt; qh : BigQueue.enqueue(bytes)\nend\n\nbqm -&gt;&gt; rl : writeAheadLog(LedgerLogEntry, PUBLISH)\\n[async Mono, fire-and-forget]\nrl -&gt; mli : asyncAddEntry(bytes, callback)\nmli -&gt; bk : BookKeeper write\n\nalt BookKeeper success\n  bk --&gt; mli : AddCallback.addComplete()\n  mli --&gt; rl : persist LedgerRecord in DB\nelse BookKeeper failure\n  mli --&gt; rl : AddCallback.addFailed()\n  rl -&gt; db : INSERT INTO enqueue_record_{queue}\\n[SQL fallback]\nend\n\nqc --&gt; prod : 200 OK (fire-and-forget)\n@enduml\n</code></pre> <p>Fire-and-Forget</p> <p>The HTTP response is returned to the producer before the WAL write completes. Durability is guaranteed by the async WAL \u2014 if the broker crashes before the WAL write, the message is recovered from any in-memory BigQueue state or the SQL fallback.</p>"},{"location":"architecture/message-flow/#pass-through-gateway","title":"Pass-Through Gateway","text":"<p>When a consumer is available and TPS is within the configured limit, the broker acts as a transparent gateway \u2014 no buffering occurs.</p> <pre><code>@startuml\n!theme plain\nskinparam backgroundColor #FAFAFA\nskinparam defaultFontName Inter\n\ntitle \"Pass-Through Gateway Decision\"\n\nstart\n\n:Receive publish request;\n:Lookup queue consumers\\n(ListenerHolder);\n\nif (Consumer registered and healthy?) then (yes)\n  :Check global TPS\\n(RedisGlobalRateLimiter);\n  if (TPS within limit?) then (yes)\n    :Check in-flight count\\n(QueueHolder.inFlight());\n    if (In-flight &lt; threshold?) then (yes)\n      #palegreen:Pass-through delivery\\n(skip BigQueue);\n      :WAL write (PUBLISH, async);\n      :HTTP POST to consumer;\n    else (no)\n      #lightyellow:Buffer in BigQueue;\n    endif\n  else (no)\n    #lightyellow:Buffer in BigQueue;\n  endif\nelse (no)\n  #lightyellow:Buffer in BigQueue;\nendif\n\n:Return 200 to producer;\nstop\n@enduml\n</code></pre>"},{"location":"architecture/message-flow/#consume-path-buffered-queue-drain","title":"Consume Path \u2014 Buffered Queue Drain","text":"<p>When messages accumulate in BigQueue (consumer down, TPS exceeded, or in-flight threshold hit), <code>QueueHolder</code>'s scheduler continuously drains the queue and pushes to consumers.</p> <pre><code>@startuml\n!theme plain\nskinparam backgroundColor #FAFAFA\nskinparam defaultFontName Inter\nskinparam sequenceMessageAlign center\n\ntitle \"Consume Path \u2014 Queue Drain \u2192 Consumer\"\n\nparticipant \"QueueMonitorService\\n(every 5 s)\" as qms\nparticipant \"QueueHolder\\n(Scheduler)\" as qh\nparticipant \"BigQueue\" as bq\nparticipant \"BigQueueManager\" as bqm\nparticipant \"RecordLedger\\n(WAL)\" as rl\ndatabase \"Apache BookKeeper\" as bk\ndatabase \"MariaDB\\ndequeue_record\" as db\nparticipant \"ListenerHolder\\n(round-robin)\" as lh\nparticipant \"ReactiveMessageHandler\\n(WebClient)\" as rmh\nactor \"Consumer\\n(Vert.x HTTP)\" as cons\n\nqms -&gt; qh : trigger drain if queue non-empty\nqh -&gt; qh : createScheduleIfNotExist()\n\nloop every 1\u20131000 ms (adaptive)\n  qh -&gt; bq : dequeue() \u2192 bytes\n  bq --&gt; qh : BigQueueTextMessage\n\n  qh -&gt; bqm : handleMessage(bytes, queue)\n  bqm -&gt; rl : writeAheadLog(LedgerLogEntry, CONSUME)\\n[async]\n  rl -&gt; bk : asyncAddEntry\n\n  alt BookKeeper success\n    bk --&gt; rl : success callback\n  else BookKeeper failure\n    rl -&gt; db : INSERT INTO dequeue_record_{queue}\n  end\n\n  bqm -&gt; lh : selectConsumer() [round-robin]\n  lh --&gt; bqm : NamedConsumer(host, port)\n  bqm -&gt; rmh : handle(message, consumer)\n  rmh -&gt; cons : HTTP POST {message body}\n\n  alt Consumer 2xx\n    cons --&gt; rmh : 200 OK\n    rmh --&gt; bqm : DeliveryAcknowledgement.SUCCESS\n    note right: message confirmed delivered\n  else Consumer error / timeout\n    cons --&gt; rmh : 5xx / timeout\n    rmh -&gt; rmh : retry (up to 3\u00d7)\n    alt Retries exhausted\n      rmh --&gt; bqm : FAILURE\n      bqm -&gt; lh : blacklist consumer\n      note right: try next consumer\n    end\n  end\nend\n@enduml\n</code></pre>"},{"location":"architecture/message-flow/#consumer-registration-flow","title":"Consumer Registration Flow","text":"<pre><code>@startuml\n!theme plain\nskinparam backgroundColor #FAFAFA\n\ntitle \"Consumer Registration\"\n\nactor \"Consumer App\" as cons\nparticipant \"QueueController\\nPOST /subscribe/{queue}\" as qc\nparticipant \"BigQueueManager\" as bqm\nparticipant \"ListenerHolder\" as lh\ndatabase \"etcd\\nConsumerRegistry\" as etcd\n\ncons -&gt; qc : POST /api/queue/subscribe/{queue}\\n{host, port, tps}\nqc -&gt; bqm : registerListener(queue, host, port, tps)\nbqm -&gt; lh : add NamedConsumer(host, port)\nbqm -&gt; etcd : register consumer in QueueConsumerRegistry\nqc --&gt; cons : 200 OK\n\nnote over lh\n  ListenerHolder keeps an ordered list.\n  Round-robin selects the next healthy consumer\n  on each delivery attempt.\nend note\n@enduml\n</code></pre>"},{"location":"architecture/message-flow/#consumer-deregistration-failover","title":"Consumer Deregistration &amp; Failover","text":"<pre><code>@startuml\n!theme plain\nskinparam backgroundColor #FAFAFA\n\ntitle \"Consumer Failover\"\n\nparticipant \"ReactiveMessageHandler\" as rmh\nparticipant \"ConsumerMonitorService\" as cms\nparticipant \"ListenerHolder\" as lh\nparticipant \"QueueFailoverService\" as qfs\ndatabase \"etcd\" as etcd\n\nrmh -&gt; rmh : HTTP POST \u2192 3\u00d7 consecutive failures\nrmh -&gt; lh : blacklist(consumer)\n\ncms -&gt; lh : health probe (scheduled)\nlh --&gt; cms : blacklisted consumers list\n\ncms -&gt; qfs : initiateFailover(queue, failedConsumer)\nqfs -&gt; etcd : deregister consumer\nqfs -&gt; lh : remove from active rotation\n\nnote over lh\n  Remaining consumers absorb the load.\n  TPS is rebalanced across active nodes.\nend note\n@enduml\n</code></pre>"},{"location":"architecture/message-flow/#end-to-end-sequence-combined-view","title":"End-to-End Sequence (Combined View)","text":"<pre><code>@startuml\n!theme plain\nskinparam backgroundColor #FAFAFA\nskinparam defaultFontName Inter\n\ntitle \"End-to-End Message Flow\"\n\nactor Producer\nactor Consumer\n\nbox \"Broker Pod\" #EEF\n  participant Controller\n  participant Manager\n  participant QueueHolder\n  participant WAL\n  participant Delivery\nend box\n\nbox \"Storage\" #FEF\n  database BookKeeper\n  database BigQueue\n  database MariaDB\nend box\n\nProducer -&gt; Controller : HTTP POST message\nController -&gt; Manager : publishtoPipe()\nManager -&gt; WAL : WAL write (async)\nWAL -&gt; BookKeeper : asyncAddEntry\n\nalt Consumer available + TPS OK\n  Manager -&gt; Delivery : direct push\n  Delivery -&gt; Consumer : HTTP POST\nelse Buffer path\n  Manager -&gt; QueueHolder : enqueue\n  QueueHolder -&gt; BigQueue : write to disk\n  ...scheduler fires...\n  QueueHolder -&gt; Manager : dequeue + handleMessage\n  Manager -&gt; WAL : WAL write (dequeue)\n  Manager -&gt; Delivery : push to consumer\n  Delivery -&gt; Consumer : HTTP POST\nend\n\nConsumer --&gt; Delivery : 200 OK\nController --&gt; Producer : 200 OK (fire-and-forget)\n@enduml\n</code></pre>"},{"location":"architecture/overview/","title":"System Overview","text":""},{"location":"architecture/overview/#design-philosophy","title":"Design Philosophy","text":"<p>The broker is built around three core principles:</p> <ol> <li>No-shared-nothing per pod \u2014 each broker pod is fully autonomous with its own local queue storage. There is no direct pod-to-pod communication for message data.</li> <li>Durability before delivery \u2014 every enqueue and dequeue is logged to a distributed Write-Ahead Log (Apache BookKeeper) before the operation is acknowledged.</li> <li>Transparent pass-through \u2014 when a consumer is healthy and within TPS limits, the broker acts as a thin gateway: the message flows directly from producer to consumer without accumulating in the local queue.</li> </ol>"},{"location":"architecture/overview/#high-level-component-map","title":"High-Level Component Map","text":"<pre><code>@startuml\n!theme plain\nskinparam backgroundColor #FAFAFA\nskinparam defaultFontName Inter\nskinparam packageStyle rectangle\n\nleft to right direction\n\nactor \"Producer\\n(HTTP Client)\" as prod\nactor \"Consumer\\n(Vert.x HTTP)\" as cons\n\npackage \"Broker Pod\" {\n\n  package \"Ingress Layer\" {\n    [QueueController\\nPOST /api/queue/publish/{queue}] as qc\n  }\n\n  package \"Core Queue Engine\" {\n    [BigQueueManager] as bqm\n    [QueueContainer\\n(Lazy-init, per queue)] as qcon\n    [QueueHolder\\n(BigQueue + RateLimiter + Scheduler)] as qh\n    [ListenerHolder\\n(Round-robin consumers)] as lh\n  }\n\n  package \"Delivery Layer\" {\n    [ReactiveMessageHandler\\n(WebClient HTTP pool)] as rmh\n  }\n\n  package \"WAL Layer\" {\n    [RecordLedger] as rl\n    [ManagedLedgerImpl\\n(Pulsar-aligned)] as mli\n  }\n\n  package \"Recovery &amp; Monitor\" {\n    [RecoveryService\\n(Scheduled ledger scan)] as rs\n    [QueueMonitorService\\n(5 s polling)] as qms\n    [ConsumerMonitorService] as cms\n  }\n\n  package \"Distributed Coordination\" {\n    [BrokerCommander\\n(Redis pub/sub)] as bc\n    [RedisGlobalRateLimiter\\n(Bucket4j)] as rrl\n    [BrokerRegistration\\n(etcd heartbeat)] as br\n  }\n\n  package \"Statistics\" {\n    [LocalStatisticService] as lss\n    [AggrigatedStatisticService] as agg\n  }\n}\n\ndatabase \"Apache BookKeeper\" as bk\ndatabase \"MariaDB\\n(Recovery Tables)\" as db\ndatabase \"Redis\" as redis\ndatabase \"etcd\" as etcd\ndatabase \"BigQueue Files\\n(disk-backed)\" as bqf\n\nprod --&gt; qc : HTTP POST\nqc --&gt; bqm\nbqm --&gt; qcon\nqcon --&gt; qh\nqh --&gt; bqf\nqh --&gt; lh\nlh --&gt; rmh\nrmh --&gt; cons : HTTP POST\n\nbqm --&gt; rl\nrl --&gt; mli\nmli --&gt; bk : asyncAddEntry\nbk ..&gt; db : SQL fallback\n\nbqm --&gt; rrl\nrrl --&gt; redis\n\nbc --&gt; redis\nbr --&gt; etcd\n\nrs --&gt; bk : scan on restart\nrs --&gt; db : residual cleanup\nqms --&gt; bqm : monitor queues\n\nlss --&gt; agg\n@enduml\n</code></pre>"},{"location":"architecture/overview/#component-responsibilities","title":"Component Responsibilities","text":""},{"location":"architecture/overview/#ingress-queuecontroller","title":"Ingress \u2014 <code>QueueController</code>","text":"<p>REST endpoint that accepts protobuf-encoded messages from producers. Delegates immediately to <code>BigQueueManager</code> and returns a fire-and-forget acknowledgement. The actual durability work happens asynchronously on the WAL layer.</p> <p>Endpoint: <code>POST /api/queue/publish/{queue}</code></p>"},{"location":"architecture/overview/#core-queue-engine","title":"Core Queue Engine","text":"Class Role <code>BigQueueManager</code> Central orchestrator \u2014 publish, consume, listener registration, recovery <code>QueueContainer</code> Lazy-initialises one <code>QueueHolder</code> per queue name <code>QueueHolder</code> Wraps a <code>BigQueue</code> on disk; owns the per-queue <code>ScheduledFuture</code> that drains the queue and the <code>RateLimiter</code> for local TPS control <code>ListenerHolder</code> Tracks registered consumers for a queue; implements round-robin selection and consumer blacklisting"},{"location":"architecture/overview/#wal-layer-recordledger-managedledgerimpl","title":"WAL Layer \u2014 <code>RecordLedger</code> / <code>ManagedLedgerImpl</code>","text":"<p>Every publish and consume event is written to a BookKeeper ledger (the WAL) before the operation is committed to the local BigQueue. This ensures that no message is lost even if the broker pod crashes mid-operation.</p> <p><code>ManagedLedgerImpl</code> is modelled directly on the Apache Pulsar implementation, providing:</p> <ul> <li>Automatic ledger rotation (by entry count, size, or time)</li> <li>Async writes with callbacks</li> <li>SQL fallback when BookKeeper is unavailable</li> </ul>"},{"location":"architecture/overview/#delivery-layer-reactivemessagehandler","title":"Delivery Layer \u2014 <code>ReactiveMessageHandler</code>","text":"<p>A non-blocking HTTP client (Spring <code>WebClient</code>) that pushes messages to consumer endpoints. Each queue gets its own connection pool tuned to the queue's configured TPS:</p> <pre><code>maxConnections  = max(tps, 2000)\npendingAcquire  = tps \u00d7 10\nmaxIdleTime     = 30 s\nresponseTimeout = 10 s\n</code></pre>"},{"location":"architecture/overview/#recovery-recoveryservice","title":"Recovery \u2014 <code>RecoveryService</code>","text":"<p>On broker restart, <code>RecoveryService</code> scans all ledger entries that were written but not yet fully processed (no matching dequeue record). It replays these entries to restore the correct queue state. See Recovery for the full algorithm.</p>"},{"location":"architecture/overview/#distributed-coordination","title":"Distributed Coordination","text":"Component Mechanism Purpose <code>BrokerRegistration</code> etcd heartbeat Self-registration; other nodes discover active brokers <code>BrokerCommander</code> Redis pub/sub (<code>broker-command</code> topic) Broadcast delete / move / unlock commands to all pods <code>RedisGlobalRateLimiter</code> Bucket4j + Redis Enforce TPS limits across all pods for the same queue"},{"location":"architecture/overview/#data-stores","title":"Data Stores","text":"<pre><code>@startuml\n!theme plain\nskinparam backgroundColor #FAFAFA\n\nrectangle \"Apache BookKeeper\" as bk {\n  rectangle \"Ledger (per queue partition)\" as led\n  rectangle \"Entry = LedgerLogEntry\\n(enqueue or dequeue action)\" as ent\n  led --&gt; ent\n}\n\nrectangle \"MariaDB\" as db {\n  rectangle \"enqueue_record_{queue}\" as er\n  rectangle \"dequeue_record_{queue}\" as dr\n  rectangle \"ledger_record\" as lr\n}\n\nrectangle \"BigQueue Files\" as bq {\n  rectangle \"index file\" as idx\n  rectangle \"data pages (mmap)\" as dp\n  idx --&gt; dp\n}\n\nrectangle \"Redis\" as redis {\n  rectangle \"broker-command (pub/sub)\" as cmd\n  rectangle \"rate limit buckets (Bucket4j)\" as rl\n  rectangle \"queue lock keys\" as lk\n}\n\nrectangle \"etcd\" as etcd {\n  rectangle \"broker node registry\" as bnr\n  rectangle \"queue metadata\" as qm\n  rectangle \"consumer registry\" as cr\n}\n@enduml\n</code></pre> Store What is persisted BookKeeper WAL \u2014 every enqueue/dequeue log entry MariaDB <code>enqueue_record_*</code> Recovery: enqueue events from processed ledgers MariaDB <code>dequeue_record_*</code> Recovery: dequeue events; <code>DELETE \u2026 RETURNING</code> for delivery MariaDB <code>ledger_record</code> Maps ledger IDs to queues BigQueue files In-flight messages on local disk (memory-mapped) Redis Global rate-limit state; distributed commands etcd Node discovery; queue/consumer metadata"},{"location":"architecture/recovery/","title":"Recovery","text":"<p>When a broker pod restarts, it must reconstruct the correct queue state from the Write-Ahead Log. The recovery process ensures that no messages are lost and no messages are delivered twice.</p>"},{"location":"architecture/recovery/#recovery-overview","title":"Recovery Overview","text":"<p>The broker uses a two-tier WAL approach for recovery:</p> <ol> <li>BookKeeper ledgers \u2014 primary source of truth (expensive, high-performance)</li> <li>MariaDB tables \u2014 secondary source (cheap, persistent, easier to query)</li> </ol> <p>During normal operation, every enqueue and dequeue is written to both a BookKeeper ledger entry and (on success) to SQL recovery tables. On restart, the broker reconciles these two sources to determine what messages are still in the queue.</p>"},{"location":"architecture/recovery/#storage-migration-expensive-cheap","title":"Storage Migration: Expensive \u2192 Cheap","text":"<pre><code>@startuml\n!theme plain\nskinparam backgroundColor #FAFAFA\nskinparam defaultFontName Inter\n\ntitle \"Ledger-to-SQL Storage Migration\"\n\nstart\n\n:Broker running normally;\n\nrepeat\n  :RecoveryService scheduled scan;\n  :Iterate each open ledger for queue;\n  :Read ledger entries;\n\n  fork\n    :Extract PUBLISH entries;\n    :Write to enqueue_record_{queue};\n  fork again\n    :Extract CONSUME entries;\n    :Write to dequeue_record_{queue};\n  end fork\n\n  :Mark ledger as processed\\n(LedgerTrackingRegistry);\n  :Ledger can now be garbage collected;\nrepeat while (more ledgers?)\n\nstop\n@enduml\n</code></pre> <p>BookKeeper ledgers are expensive storage \u2014 they occupy bookie disk space and require an ensemble. Once processed into MariaDB tables, the ledger data moves to cheap storage (relational rows) and the ledger itself can be deleted.</p>"},{"location":"architecture/recovery/#restart-recovery-algorithm","title":"Restart Recovery Algorithm","text":"<pre><code>@startuml\n!theme plain\nskinparam backgroundColor #FAFAFA\nskinparam defaultFontName Inter\n\ntitle \"Broker Restart Recovery\"\n\nstart\n\n:Pod starts;\n:RecoveryService.init();\n\n:Query LedgerTrackingRegistry\\nfor unprocessed ledgers;\n\nif (Unprocessed ledgers exist?) then (yes)\n  repeat\n    :Open ledger from BookKeeper;\n    :Read all entries;\n\n    fork\n      :PUBLISH entries \u2192\\nINSERT INTO enqueue_record_{queue};\n    fork again\n      :CONSUME entries \u2192\\nINSERT INTO dequeue_record_{queue};\n    end fork\n\n    :Mark ledger as processed;\n  repeat while (more unprocessed ledgers?)\nelse (no)\n  :All ledgers already migrated to SQL;\nendif\n\n:Reconcile SQL tables;\nnote right\n  Messages remaining =\n  enqueue_record rows with no\n  matching dequeue_record row\nend note\n\n:Remaining rows = actual queue state;\n:Re-enqueue into local BigQueue;\n\n:Queue ready for production;\nstop\n@enduml\n</code></pre>"},{"location":"architecture/recovery/#sql-table-reconciliation","title":"SQL Table Reconciliation","text":"<p>The recovery logic is essentially a set difference:</p> <pre><code>Queue State = enqueue_record_{queue}  EXCEPT  dequeue_record_{queue}\n</code></pre> <p>Messages in <code>enqueue_record</code> but not in <code>dequeue_record</code> were produced but never successfully consumed. They must be re-enqueued.</p> <pre><code>@startuml\n!theme plain\nskinparam backgroundColor #FAFAFA\n\ntitle \"Recovery Reconciliation\"\n\nrectangle \"enqueue_record_{queue}\" as er {\n  card \"msg-001 (enqueued)\" as e1\n  card \"msg-002 (enqueued)\" as e2\n  card \"msg-003 (enqueued)\" as e3\n  card \"msg-004 (enqueued)\" as e4\n}\n\nrectangle \"dequeue_record_{queue}\" as dr {\n  card \"msg-001 (consumed)\" as d1\n  card \"msg-003 (consumed)\" as d3\n}\n\nrectangle \"Recovered Messages\\n(re-enqueue to BigQueue)\" as rm {\n  card \"msg-002\" as r2 #palegreen\n  card \"msg-004\" as r4 #palegreen\n}\n\ne1 ..&gt; d1 : matched \u2014 skip\ne2 --&gt; r2 : no match \u2014 recover\ne3 ..&gt; d3 : matched \u2014 skip\ne4 --&gt; r4 : no match \u2014 recover\n@enduml\n</code></pre>"},{"location":"architecture/recovery/#consumer-available-recovery-path","title":"Consumer-Available Recovery Path","text":"<p>When a consumer is registered for a queue at the time of recovery (rather than loading into BigQueue), messages can be delivered directly from the SQL table using a DELETE \u2026 RETURNING pattern:</p> <pre><code>@startuml\n!theme plain\nskinparam backgroundColor #FAFAFA\nskinparam sequenceMessageAlign center\n\ntitle \"SQL-Driven Consumer Delivery (Recovery)\"\n\nparticipant \"RecoveryService\" as rs\nparticipant \"QueueMonitorService\" as qms\ndatabase \"MariaDB\\nenqueue_record_{queue}\" as db\nparticipant \"ReactiveMessageHandler\" as rmh\nactor \"Consumer\" as cons\n\nrs -&gt; db : find unmatched enqueue_record rows\nrs -&gt; qms : notify: queue has residual messages\nqms -&gt; rs : consumer available?\n\nalt Consumer registered\n  loop for each residual message\n    rs -&gt; db : DELETE FROM enqueue_record_{queue}\\nWHERE id = ?\\nRETURNING message_payload\n    db --&gt; rs : message_payload (atomic \u2014 no double delivery)\n    rs -&gt; rmh : deliver message to consumer\n    rmh -&gt; cons : HTTP POST\n    cons --&gt; rmh : 200 OK\n    note right: row deleted atomically;\\nno re-delivery on crash\n  end\nelse No consumer\n  rs -&gt; rs : enqueue to local BigQueue\\nfor later delivery\nend\n@enduml\n</code></pre> <p>The <code>DELETE \u2026 RETURNING</code> pattern is atomically safe: if the broker crashes between the delete and the HTTP POST, the row is gone and the message is lost. To guard against this, the message is written to BigQueue before the delete in non-consumer-available paths.</p>"},{"location":"architecture/recovery/#queue-deletion-cleanup","title":"Queue Deletion Cleanup","text":"<pre><code>@startuml\n!theme plain\nskinparam backgroundColor #FAFAFA\n\ntitle \"Queue Deletion \u2014 Distributed Cleanup\"\n\nactor \"Admin\" as admin\nparticipant \"QueueController\\nDELETE /api/queue/{name}\" as qc\nparticipant \"BigQueueManager\" as bqm\nparticipant \"BrokerCommander\\n(Redis pub/sub)\" as bc\nparticipant \"All Broker Pods\" as pods\ndatabase \"etcd\" as etcd\ndatabase \"MariaDB\" as db\ndatabase \"BigQueue Files\" as bqf\n\nadmin -&gt; qc : DELETE request\nqc -&gt; bqm : requestQueueDeletion(queueName)\nbqm -&gt; etcd : mark queue for deletion\nbqm -&gt; bc : broadcast DeleteCommand\\n(broker-command topic)\n\nbc -&gt;&gt; pods : DeleteCommand received\n\npods -&gt; bqm : purgeQueue(queueName)\nbqm -&gt; bqf : delete local BigQueue files\nbqm -&gt; db : DROP TABLE enqueue_record_{queue}\nbqm -&gt; db : DROP TABLE dequeue_record_{queue}\nbqm -&gt; etcd : remove queue metadata\n@enduml\n</code></pre>"},{"location":"architecture/recovery/#recovery-service-configuration","title":"Recovery Service Configuration","text":"Parameter Default Description <code>bigbro.broker.recovery.timeout</code> <code>2</code> Dequeue timeout in seconds when scanning for residuals Scan interval <code>1 s</code> <code>bufferRecovery()</code> scheduled task frequency Ledger stats cache <code>5 s</code> <code>collectPendingLedgerStats()</code> refresh interval"},{"location":"architecture/recovery/#pending-message-count","title":"Pending Message Count","text":"<p><code>RecoveryService.pendingMessageToBeRecovered()</code> counts unprocessed ledger entries across all queues. This is used by:</p> <ul> <li><code>QueueMonitorService</code> to decide whether to trigger recovery</li> <li><code>AggrigatedStatisticService</code> to expose recovery backlog metrics</li> <li>Liveness/readiness probes to delay traffic until recovery completes</li> </ul>"},{"location":"architecture/scaling/","title":"Scaling","text":""},{"location":"architecture/scaling/#no-shared-nothing-architecture","title":"No-Shared-Nothing Architecture","text":"<p>Each broker pod is fully autonomous. There is no inter-pod data sharing for message storage. Pods only communicate through:</p> <ul> <li>etcd \u2014 for node discovery and queue/consumer metadata</li> <li>Redis \u2014 for distributed rate limiting and command broadcast</li> <li>MariaDB \u2014 shared recovery tables (one table-set per queue)</li> <li>BookKeeper \u2014 shared WAL (each pod writes its own ledger entries)</li> </ul> <pre><code>@startuml\n!theme plain\nskinparam backgroundColor #FAFAFA\nskinparam defaultFontName Inter\n\ntitle \"No-Shared-Nothing Pod Topology\"\n\npackage \"Pod A\" {\n  [BigQueueManager A] as bqmA\n  [BigQueue Files A\\n(local disk)] as bqfA\n  [QueueHolder A] as qhA\n  bqmA --&gt; qhA\n  qhA --&gt; bqfA\n}\n\npackage \"Pod B\" {\n  [BigQueueManager B] as bqmB\n  [BigQueue Files B\\n(local disk)] as bqfB\n  [QueueHolder B] as qhB\n  bqmB --&gt; qhB\n  qhB --&gt; bqfB\n}\n\npackage \"Pod C\" {\n  [BigQueueManager C] as bqmC\n  [BigQueue Files C\\n(local disk)] as bqfC\n  [QueueHolder C] as qhC\n  bqmC --&gt; qhC\n  qhC --&gt; bqfC\n}\n\ndatabase \"Apache BookKeeper\\n(shared WAL)\" as bk\ndatabase \"Redis\\n(rate limit + commands)\" as redis\ndatabase \"etcd\\n(discovery + metadata)\" as etcd\ndatabase \"MariaDB\\n(recovery tables)\" as db\n\nbqmA --&gt; bk\nbqmB --&gt; bk\nbqmC --&gt; bk\n\nbqmA --&gt; redis\nbqmB --&gt; redis\nbqmC --&gt; redis\n\nbqmA --&gt; etcd\nbqmB --&gt; etcd\nbqmC --&gt; etcd\n\nbqmA --&gt; db\nbqmB --&gt; db\nbqmC --&gt; db\n\nnote bottom of bk\n  Each pod writes to its\n  own ledger partitions.\n  No inter-pod ledger sharing.\nend note\n@enduml\n</code></pre>"},{"location":"architecture/scaling/#horizontal-scale-out","title":"Horizontal Scale-Out","text":"<p>Adding a new broker pod requires no configuration changes. The pod:</p> <ol> <li>Registers itself in etcd via <code>BrokerRegistration</code> (heartbeat every N seconds)</li> <li>Is discovered by other pods through <code>NodeController</code> (<code>GET /api/node</code>)</li> <li>Begins receiving traffic from the load balancer immediately</li> <li>The global rate limiter in Redis automatically distributes TPS across all active pods</li> </ol> <pre><code>@startuml\n!theme plain\nskinparam backgroundColor #FAFAFA\n\ntitle \"New Pod Joins Cluster\"\n\nparticipant \"New Pod\" as np\nparticipant \"etcd\" as etcd\nparticipant \"Load Balancer\" as lb\nparticipant \"Redis\\nRate Limiter\" as redis\nparticipant \"Other Pods\" as pods\n\nnp -&gt; etcd : register heartbeat\\n(BrokerRegistration)\netcd --&gt; pods : pod-list updated\nlb -&gt; np : begin routing traffic\nnp -&gt; redis : participate in global TPS bucket\nnote over redis\n  Per-queue TPS is split across active pods:\n  effectiveTPS = configuredTPS / activePodCount\nend note\n@enduml\n</code></pre>"},{"location":"architecture/scaling/#queue-instance-tracking","title":"Queue Instance Tracking","text":"<p>A queue can be active on one pod at a time for a given partition. <code>QueueInstanceTrackingRegistry</code> in etcd ensures only one pod owns a queue instance:</p> <pre><code>@startuml\n!theme plain\nskinparam backgroundColor #FAFAFA\n\ntitle \"Queue Instance Ownership\"\n\nparticipant \"Pod A\" as podA\nparticipant \"Pod B\" as podB\ndatabase \"etcd\\nQueueInstanceTrackingRegistry\" as etcd\n\npodA -&gt; etcd : acquire lock for queue:orders:partition-0\netcd --&gt; podA : GRANTED\n\npodB -&gt; etcd : acquire lock for queue:orders:partition-0\netcd --&gt; podB : DENIED (already owned)\n\nnote over podA, podB\n  Pod B routes publishes to Pod A,\n  or waits for lock expiry/release.\n  Prevents duplicate delivery from two pods.\nend note\n@enduml\n</code></pre>"},{"location":"architecture/scaling/#tps-distribution-across-pods","title":"TPS Distribution Across Pods","text":"<p>The global rate limiter uses Redis + Bucket4j to enforce a per-queue TPS limit globally, even when multiple pods serve the same queue:</p> <pre><code>@startuml\n!theme plain\nskinparam backgroundColor #FAFAFA\n\ntitle \"Global TPS Rate Limiting\"\n\nactor \"Producer\" as prod\nparticipant \"Pod A\\nRateLimiter\" as podA\nparticipant \"Pod B\\nRateLimiter\" as podB\nparticipant \"Pod C\\nRateLimiter\" as podC\ndatabase \"Redis\\nBucket (queue:orders, 1000 TPS)\" as redis\n\nprod --&gt; podA : request\nprod --&gt; podB : request\nprod --&gt; podC : request\n\npodA -&gt; redis : tryConsume(1)\npodB -&gt; redis : tryConsume(1)\npodC -&gt; redis : tryConsume(1)\n\nredis --&gt; podA : OK (bucket has tokens)\nredis --&gt; podB : OK\nredis --&gt; podC : REJECTED (bucket empty)\n\npodC --&gt; prod : 429 Too Many Requests\n\nnote over redis\n  All pods share one bucket per queue.\n  Total across all pods never exceeds\n  the configured TPS limit.\nend note\n@enduml\n</code></pre>"},{"location":"architecture/scaling/#kubernetes-deployment","title":"Kubernetes Deployment","text":"<p>The broker is deployed as a <code>Deployment</code> (or <code>StatefulSet</code> for stable pod identity) in Kubernetes. Local BigQueue files are backed by a <code>PersistentVolumeClaim</code> per pod.</p> <pre><code>@startuml\n!theme plain\nskinparam backgroundColor #FAFAFA\n\ntitle \"Kubernetes Topology\"\n\npackage \"Kubernetes Cluster\" {\n\n  package \"broker Deployment\" {\n    rectangle \"broker-pod-0\\n(PVC: queue-data-0)\" as p0\n    rectangle \"broker-pod-1\\n(PVC: queue-data-1)\" as p1\n    rectangle \"broker-pod-2\\n(PVC: queue-data-2)\" as p2\n  }\n\n  rectangle \"Service\\n(ClusterIP / LoadBalancer)\" as svc\n  rectangle \"HPA\\n(CPU / custom metrics)\" as hpa\n\n  svc --&gt; p0\n  svc --&gt; p1\n  svc --&gt; p2\n  hpa ..&gt; p0 : scale out/in\n}\n\ncloud \"BookKeeper Ensemble\" as bk\ncloud \"Redis Sentinel/Cluster\" as redis\ncloud \"etcd Cluster\" as etcd\ncloud \"MariaDB (Galera)\" as db\n\np0 --&gt; bk\np1 --&gt; bk\np2 --&gt; bk\np0 --&gt; redis\np1 --&gt; redis\np2 --&gt; redis\np0 --&gt; etcd\np1 --&gt; etcd\np2 --&gt; etcd\np0 --&gt; db\np1 --&gt; db\np2 --&gt; db\n@enduml\n</code></pre>"},{"location":"architecture/scaling/#helm-values","title":"Helm Values","text":"<p>The broker ships with a Helm chart under <code>helmchart/</code>. Key scaling values:</p> <pre><code>replicaCount: 3\n\nresources:\n  requests:\n    cpu: \"500m\"\n    memory: \"1Gi\"\n  limits:\n    cpu: \"2\"\n    memory: \"4Gi\"\n\npersistence:\n  enabled: true\n  storageClass: \"fast-ssd\"\n  size: \"50Gi\"\n\nautoscaling:\n  enabled: true\n  minReplicas: 2\n  maxReplicas: 10\n  targetCPUUtilizationPercentage: 70\n</code></pre>"},{"location":"architecture/wal/","title":"Write-Ahead Log (WAL)","text":"<p>Every message operation \u2014 publish and consume \u2014 is durably recorded in a Write-Ahead Log before the operation is considered committed. The WAL is built on Apache BookKeeper, with an automatic SQL fallback to MariaDB when BookKeeper is unavailable.</p>"},{"location":"architecture/wal/#wal-architecture","title":"WAL Architecture","text":"<pre><code>@startuml\n!theme plain\nskinparam backgroundColor #FAFAFA\nskinparam defaultFontName Inter\n\npackage \"WAL Layer\" {\n  class RecordLedger {\n    + writeAheadLog(entry: LedgerLogEntry, action: WALAction): Mono&lt;Void&gt;\n    - ledgers: Map&lt;String, ManagedLedger&gt;\n    - onLedgerCreated(queue)\n    - onLedgerClosed(ledgerId)\n  }\n\n  class ManagedLedgerImpl {\n    - state: LedgerState\n    - currentLedger: LedgerHandle\n    - config: ManagedLedgerConfig\n    + asyncAddEntry(data: byte[], callback: AddEntryCallback): void\n    - createLedger()\n    - rotateLedger()\n    - checkAndCompleteLedgerOpTask()\n  }\n\n  class ManagedLedgerConfig {\n    + ensembleSize: int\n    + writeQuorum: int\n    + ackQuorum: int\n    + maxEntriesPerLedger: long\n    + maxLedgerRolloverTimeSeconds: int\n    + metadataOperationsTimeoutSeconds: int = 30\n  }\n\n  enum LedgerState {\n    None\n    CreatingLedger\n    LedgerOpened\n    ClosingLedger\n    ClosedLedger\n    Fenced\n    Terminated\n    WriteFailed\n  }\n\n  class AddEntryOperation {\n    + data: ByteBuf\n    + callback: AddEntryCallback\n    + startTime: long\n    + timeout: Timeout\n  }\n\n  class LedgerLogEntry {\n    + queueName: String\n    + partitionId: int\n    + messageId: String\n    + payload: byte[]\n    + action: WALAction  // PUBLISH or CONSUME\n    + timestamp: Instant\n  }\n\n  RecordLedger --&gt; ManagedLedgerImpl : one per queue partition\n  ManagedLedgerImpl --&gt; ManagedLedgerConfig : configured by\n  ManagedLedgerImpl --&gt; LedgerState : state machine\n  ManagedLedgerImpl --&gt; AddEntryOperation : pending operations queue\n  RecordLedger --&gt; LedgerLogEntry : serialises to bytes\n}\n\ndatabase \"Apache BookKeeper\" as bk\ndatabase \"MariaDB\" as db\n\nManagedLedgerImpl --&gt; bk : BookKeeper client API\nRecordLedger ..&gt; db : SQL fallback on failure\n@enduml\n</code></pre>"},{"location":"architecture/wal/#ledger-state-machine","title":"Ledger State Machine","text":"<p><code>ManagedLedgerImpl</code> follows the same state machine as Apache Pulsar's managed ledger. This ensures proven correctness for concurrent ledger creation and rotation.</p> <pre><code>@startuml\n!theme plain\nskinparam backgroundColor #FAFAFA\n\n[*] --&gt; None : init\n\nNone --&gt; CreatingLedger : asyncAddEntry() called\\nwith no open ledger\n\nCreatingLedger --&gt; LedgerOpened : BookKeeper ledger created\\nsuccessfully\n\nLedgerOpened --&gt; LedgerOpened : normal writes\\n(asyncAddEntry)\n\nLedgerOpened --&gt; ClosingLedger : rotation triggered\\n(max entries / size / time)\n\nClosingLedger --&gt; CreatingLedger : old ledger closed,\\nnew ledger opening\n\nLedgerOpened --&gt; WriteFailed : consecutive write failures\n\nWriteFailed --&gt; [*] : non-recoverable\n\nLedgerOpened --&gt; Terminated : queue deleted\nTerminated --&gt; [*]\n\nnote right of LedgerOpened\n  Rotation conditions:\n  \u2022 maxEntriesPerLedger reached\n  \u2022 maxLedgerSize reached\n  \u2022 rolloverTimeSeconds elapsed\nend note\n@enduml\n</code></pre>"},{"location":"architecture/wal/#wal-write-sequence","title":"WAL Write Sequence","text":"<pre><code>@startuml\n!theme plain\nskinparam backgroundColor #FAFAFA\nskinparam sequenceMessageAlign center\n\ntitle \"WAL Write Sequence (asyncAddEntry)\"\n\nparticipant \"BigQueueManager\" as bqm\nparticipant \"RecordLedger\" as rl\nparticipant \"ManagedLedgerImpl\" as mli\nparticipant \"AddEntryOperation\\n(pending queue)\" as aeo\nparticipant \"BookKeeper Client\" as bkc\ndatabase \"BookKeeper Ensemble\" as bk\ndatabase \"MariaDB\" as db\n\nbqm -&gt;&gt; rl : writeAheadLog(LedgerLogEntry, action)\\n[returns Mono&lt;Void&gt;, subscribed async]\nrl -&gt; rl : serialise LedgerLogEntry to bytes\nrl -&gt; mli : asyncAddEntry(bytes, AddEntryCallback)\n\nalt Ledger is OPEN\n  mli -&gt; aeo : create AddEntryOperation\\n(start timeout timer)\n  mli -&gt; bkc : lh.asyncAddEntry(data, callback)\n  bkc -&gt; bk : write to ensemble\\n(ensembleSize=1, writeQuorum=1)\n  bk --&gt; bkc : ackQuorum satisfied\n  bkc --&gt; mli : AddCallback.addComplete(rc, lh, entryId)\n  mli -&gt; aeo : cancel timeout\n  mli --&gt; rl : AddEntryCallback.addComplete(position)\n  rl -&gt; db : INSERT ledger_record (ledgerId, queue, entryId)\n  rl --&gt; bqm : Mono completes \u2192 metric.ack++\n\nelse Ledger is CREATING (rotation in progress)\n  mli -&gt; aeo : queue operation (pendingAddEntries)\n  note right: replayed after new ledger opens\n\nelse BookKeeper write failed\n  bk --&gt; bkc : error\n  bkc --&gt; mli : AddCallback.addFailed()\n  mli --&gt; rl : AddEntryCallback.addFailed(exception)\n  rl -&gt; db : INSERT INTO enqueue_record_{queue} OR\\nINSERT INTO dequeue_record_{queue}\\n[SQL fallback]\n  rl --&gt; bqm : Mono completes \u2192 metric.nack++\nend\n@enduml\n</code></pre>"},{"location":"architecture/wal/#wal-entry-structure","title":"WAL Entry Structure","text":"<p>Each WAL entry (<code>LedgerLogEntry</code>) is serialised to bytes and stored in BookKeeper. The entry captures enough information to reconstruct the queue state during recovery.</p> Field Type Description <code>queueName</code> String Name of the queue <code>partitionId</code> int Partition within the queue <code>messageId</code> String Unique message identifier <code>payload</code> byte[] Serialised <code>BigQueueTextMessage</code> (protobuf) <code>action</code> WALAction <code>PUBLISH</code> or <code>CONSUME</code> <code>timestamp</code> Instant Wall-clock time of the operation"},{"location":"architecture/wal/#sql-fallback","title":"SQL Fallback","text":"<p>When BookKeeper is unavailable, the WAL falls back to MariaDB. This ensures zero message loss even during BookKeeper outages.</p> <pre><code>@startuml\n!theme plain\nskinparam backgroundColor #FAFAFA\n\ntitle \"SQL Fallback Path\"\n\nstart\n\n:asyncAddEntry() called;\n:BookKeeper write attempt;\n\nif (BookKeeper available?) then (yes)\n  :Write to ledger ensemble;\n  if (ACK received within 30 s?) then (yes)\n    #palegreen:Ledger entry persisted;\n    :Insert LedgerRecord in DB;\n  else (timeout)\n    #lightyellow:Timeout \u2014 fall to SQL;\n    :INSERT enqueue_record or dequeue_record;\n  endif\nelse (no)\n  #lightyellow:BookKeeper unavailable \u2014 fall to SQL;\n  :INSERT enqueue_record or dequeue_record;\nendif\n\nstop\n@enduml\n</code></pre> <p>The <code>enqueue_record_{queue}</code> and <code>dequeue_record_{queue}</code> tables serve as the recovery source of truth when broker pods restart. See Recovery for how these are consumed.</p>"},{"location":"architecture/wal/#ledger-configuration-reference","title":"Ledger Configuration Reference","text":"<pre><code># application.yml\nbigbro.broker.keeper:\n  metadataServiceUri: zk://localhost:2181/bookkeeper/ledgers\n  ensembleSize: 1        # number of bookies to stripe across\n  writeQuorum: 1         # replicas to write to\n  ackQuorum: 1           # replicas that must ack\n\n# ManagedLedgerConfig defaults (set in code)\nmaxEntriesPerLedger: 50000\nmaxLedgerRolloverTimeSeconds: 3600     # 1 hour\nmetadataOperationsTimeoutSeconds: 30\n</code></pre> <p>Production tuning</p> <p>For high-throughput deployments, increase <code>ensembleSize</code> and <code>writeQuorum</code> to 3 for replication. The <code>ackQuorum</code> should be at least <code>(writeQuorum / 2) + 1</code> for quorum safety.</p>"},{"location":"components/commands/","title":"Distributed Commands","text":"<p>The broker uses Redis pub/sub to broadcast operational commands across all pods. This allows any pod to trigger cluster-wide actions (delete a queue, move messages, invalidate caches) without tight coupling.</p>"},{"location":"components/commands/#command-architecture","title":"Command Architecture","text":"<pre><code>@startuml\n!theme plain\nskinparam backgroundColor #FAFAFA\nskinparam defaultFontName Inter\n\ninterface Command {\n  + getType(): CommandType\n  + getQueueName(): String\n  + execute(BigQueueManager): Mono&lt;Void&gt;\n  {static} + of(type, queue): Command\n}\n\nclass DeleteCommand {\n  + type: DELETE\n  + execute(): purge queue locally\n}\n\nclass MoveCommand {\n  + type: MOVE\n  + targetNode: String\n  + execute(): transfer queue ownership\n}\n\nclass UnlockCommand {\n  + type: UNLOCK\n  + execute(): invalidate distributed lock\\ncache for queue\n}\n\nclass BrokerCommander {\n  - redisTemplate: RedisTemplate\n  - topic: \"broker-command\"\n  + broadcast(command: Command): void\n  + onMessage(message): void [listener]\n}\n\nCommand &lt;|.. DeleteCommand\nCommand &lt;|.. MoveCommand\nCommand &lt;|.. UnlockCommand\n\nBrokerCommander --&gt; Command : broadcasts/receives\n@enduml\n</code></pre>"},{"location":"components/commands/#command-broadcast-receive","title":"Command Broadcast &amp; Receive","text":"<pre><code>@startuml\n!theme plain\nskinparam backgroundColor #FAFAFA\nskinparam sequenceMessageAlign center\n\ntitle \"Distributed Command Broadcast\"\n\nactor \"Admin / Broker Logic\" as admin\nparticipant \"BrokerCommander\\n(Pod A)\" as bcA\ndatabase \"Redis\\ntopic: broker-command\" as redis\nparticipant \"BrokerCommander\\n(Pod B)\" as bcB\nparticipant \"BrokerCommander\\n(Pod C)\" as bcC\nparticipant \"BigQueueManager\" as bqm\n\nadmin -&gt; bcA : broadcast(DeleteCommand{queue=\"orders\"})\nbcA -&gt; redis : PUBLISH broker-command\\n{type:DELETE, queue:orders}\n\nredis --&gt;&gt; bcA : (self \u2014 ignored)\nredis --&gt;&gt; bcB : message received\nredis --&gt;&gt; bcC : message received\n\nbcB -&gt; bcB : deserialise Command\nbcB -&gt; bqm : command.execute(bigQueueManager)\nbqm -&gt; bqm : purge local BigQueue\\nand recovery tables\n\nbcC -&gt; bcC : deserialise Command\nbcC -&gt; bqm : command.execute(bigQueueManager)\n@enduml\n</code></pre>"},{"location":"components/commands/#command-types","title":"Command Types","text":""},{"location":"components/commands/#deletecommand","title":"DeleteCommand","text":"<p>Triggered when a queue is deleted. Broadcasts to all pods to clean up local state.</p> <pre><code>@startuml\n!theme plain\nskinparam backgroundColor #FAFAFA\nskinparam sequenceMessageAlign center\n\ntitle \"DeleteCommand Execution Flow\"\n\nparticipant \"BrokerCommander\" as bc\nparticipant \"BigQueueManager\" as bqm\nparticipant \"QueueContainer\" as qcon\ndatabase \"BigQueue Files\" as bqf\ndatabase \"MariaDB\" as db\ndatabase \"etcd\" as etcd\n\nbc -&gt; bqm : DeleteCommand.execute(bqm)\nbqm -&gt; qcon : removeQueue(queueName)\nqcon -&gt; bqf : delete BigQueue directory\nbqm -&gt; db : DROP TABLE enqueue_record_{queue}\nbqm -&gt; db : DROP TABLE dequeue_record_{queue}\nbqm -&gt; etcd : remove QueueMeta\nbqm -&gt; etcd : remove QueueInstanceTracking\n@enduml\n</code></pre>"},{"location":"components/commands/#movecommand","title":"MoveCommand","text":"<p>Transfers queue ownership from one pod to another (e.g., during a rolling restart or pod eviction).</p> <pre><code>@startuml\n!theme plain\nskinparam backgroundColor #FAFAFA\nskinparam sequenceMessageAlign center\n\ntitle \"MoveCommand Execution Flow\"\n\nparticipant \"Source Pod\" as src\nparticipant \"Target Pod\" as tgt\ndatabase \"etcd\" as etcd\n\nsrc -&gt; etcd : update QueueInstanceTracking\\n(queue \u2192 targetPod)\netcd --&gt;&gt; tgt : watch event: queue assigned\ntgt -&gt; tgt : tryCreateQueue(queueName)\ntgt -&gt; tgt : begin accepting messages\nsrc -&gt; src : stop accepting messages\\nfor this queue\n@enduml\n</code></pre>"},{"location":"components/commands/#unlockcommand","title":"UnlockCommand","text":"<p>Invalidates a distributed lock or cache entry for a queue. Used after manual administrative intervention to clear stuck state.</p> <pre><code>@startuml\n!theme plain\nskinparam backgroundColor #FAFAFA\nskinparam sequenceMessageAlign center\n\ntitle \"UnlockCommand Execution Flow\"\n\nparticipant \"BrokerCommander\" as bc\nparticipant \"BigQueueManager\" as bqm\ndatabase \"Redis\\nlock:{queue}\" as redis\n\nbc -&gt; bqm : UnlockCommand.execute(bqm)\nbqm -&gt; redis : DEL lock:{queueName}\nbqm -&gt; bqm : clear local lock cache entry\nnote right: Other pods will re-acquire\\nthe lock on next operation\n@enduml\n</code></pre>"},{"location":"components/commands/#event-listener-pattern","title":"Event Listener Pattern","text":"<p>Each broker pod subscribes to the <code>broker-command</code> Redis topic through a Spring <code>MessageListenerContainer</code>:</p> <pre><code>@startuml\n!theme plain\nskinparam backgroundColor #FAFAFA\n\ntitle \"Spring Event Listener Chain\"\n\nparticipant \"RedisConfig\\n(MessageListenerContainer)\" as rlc\nparticipant \"BrokerCommander\\n(@EventListener)\" as bc\nparticipant \"BigQueueManager\" as bqm\n\nnote over rlc : registered at startup\nrlc -&gt; bc : onMessage(CommandMessage)\nbc -&gt; bc : deserialise JSON \u2192 Command\nbc -&gt; bc : publish Spring ApplicationEvent\nbc -&gt; bqm : command.execute(bqm)\n@enduml\n</code></pre>"},{"location":"components/commands/#command-serialisation","title":"Command Serialisation","text":"<p>Commands are serialised to JSON and published to Redis. The format is:</p> <pre><code>{\n  \"type\": \"DELETE\",\n  \"queueName\": \"orders\",\n  \"sourceNode\": \"broker-pod-0\",\n  \"timestamp\": \"2024-01-15T10:30:00Z\"\n}\n</code></pre>"},{"location":"components/consumer/","title":"Consumer Delivery","text":"<p>The broker pushes messages to consumers over HTTP. Consumers run a Vert.x HTTP server that the broker calls via a reactive WebClient connection pool.</p>"},{"location":"components/consumer/#consumer-registration","title":"Consumer Registration","text":"<pre><code>@startuml\n!theme plain\nskinparam backgroundColor #FAFAFA\nskinparam sequenceMessageAlign center\n\ntitle \"Consumer Registration Flow\"\n\nactor \"Consumer App\\n(Vert.x HTTP)\" as cons\nparticipant \"QueueController\" as qc\nparticipant \"BigQueueManager\" as bqm\nparticipant \"ListenerHolder\" as lh\ndatabase \"etcd\\nQueueConsumerRegistry\" as etcd\n\ncons -&gt; qc : POST /api/queue/subscribe/{queue}\\nBody: {host, port, tps}\nqc -&gt; bqm : registerListener(queue, host, port, tps)\nbqm -&gt; lh : addConsumer(NamedConsumer{host, port, tps})\nbqm -&gt; etcd : register(queue, consumer)\nlh -&gt; lh : trigger scheduler if\\nqueue has pending messages\nqc --&gt; cons : 200 OK\n@enduml\n</code></pre>"},{"location":"components/consumer/#http-delivery-reactivemessagehandler","title":"HTTP Delivery \u2014 ReactiveMessageHandler","text":"<p><code>ReactiveMessageHandler</code> manages a per-queue WebClient connection pool for non-blocking delivery. Pool parameters are tuned at queue registration time:</p> <pre><code>@startuml\n!theme plain\nskinparam backgroundColor #FAFAFA\n\ntitle \"ReactiveMessageHandler Connection Pool (per queue)\"\n\nrectangle \"ReactiveMessageHandler\" as rmh {\n  rectangle \"WebClient (queue: orders)\" as wc1 {\n    rectangle \"ConnectionProvider\\nmaxConnections=max(tps,2000)\\npendingAcquire=tps\u00d710\\nmaxIdleTime=30s\\nmaxLifeTime=60s\" as cp1\n  }\n  rectangle \"WebClient (queue: payments)\" as wc2 {\n    rectangle \"ConnectionProvider\\nmaxConnections=max(tps,2000)\\npendingAcquire=tps\u00d710\" as cp2\n  }\n}\n@enduml\n</code></pre>"},{"location":"components/consumer/#delivery-call-flow","title":"Delivery Call Flow","text":"<pre><code>@startuml\n!theme plain\nskinparam backgroundColor #FAFAFA\nskinparam sequenceMessageAlign center\n\ntitle \"HTTP Message Delivery\"\n\nparticipant \"BigQueueManager\" as bqm\nparticipant \"ReactiveMessageHandler\" as rmh\nparticipant \"WebClient\\n(per-queue pool)\" as wc\nactor \"Consumer\\n(Vert.x HTTP)\" as cons\n\nbqm -&gt; rmh : handle(message, NamedConsumer)\nrmh -&gt; rmh : resolve or create\\nWebClient for consumer.host:port\nrmh -&gt; wc : POST http://host:port/receive\\nContent-Type: application/json\\nBody: {messageId, payload, queue}\n\nalt 2xx response\n  cons --&gt; wc : 200 OK\n  wc --&gt; rmh : ClientResponse\n  rmh --&gt; bqm : DeliveryAcknowledgement.SUCCESS\n  note right of bqm : metrics.consumer.total++\nelse 5xx / connection error\n  cons --&gt; wc : 500 / IOException\n  wc --&gt; rmh : error\n  rmh -&gt; rmh : retry (RetryInterceptor,\\nup to 3 attempts)\n  alt Retries exhausted\n    rmh --&gt; bqm : DeliveryAcknowledgement.FAILURE\n    bqm -&gt; bqm : metrics.consumer.errors++\n    bqm -&gt; bqm : blacklist consumer\n  end\nelse Timeout (responseTimeout=10s)\n  rmh --&gt; bqm : FAILURE\nend\n@enduml\n</code></pre>"},{"location":"components/consumer/#retry-strategy","title":"Retry Strategy","text":"<pre><code>@startuml\n!theme plain\nskinparam backgroundColor #FAFAFA\n\ntitle \"Delivery Retry Logic\"\n\nstart\n\n:Attempt delivery (attempt 1);\n\nif (Success?) then (yes)\n  #palegreen:DeliveryAck.SUCCESS;\n  stop\nelse (no)\n  if (attempt &lt; 3?) then (yes)\n    :Wait (exponential backoff);\n    :Attempt delivery (attempt N+1);\n    backward: retry;\n  else (no, retries exhausted)\n    #lightyellow:Log failure;\n    :failureCount++ on NamedConsumer;\n    if (failureCount &gt;= 3?) then (yes)\n      #lightcoral:Blacklist consumer;\n      :Select next consumer\\n(round-robin);\n    endif\n    :DeliveryAck.FAILURE;\n    stop\n  endif\nendif\n@enduml\n</code></pre>"},{"location":"components/consumer/#consumer-blacklisting-recovery","title":"Consumer Blacklisting &amp; Recovery","text":"<pre><code>@startuml\n!theme plain\nskinparam backgroundColor #FAFAFA\nskinparam sequenceMessageAlign center\n\ntitle \"Consumer Blacklist Lifecycle\"\n\nparticipant \"ReactiveMessageHandler\" as rmh\nparticipant \"ListenerHolder\" as lh\nparticipant \"ConsumerMonitorService\\n(scheduled)\" as cms\n\nrmh -&gt; lh : reportFailure(consumer)\nlh -&gt; lh : consumer.failureCount++\n\nalt failureCount == 3\n  lh -&gt; lh : add to blacklist set\n  note right of lh : blacklisted consumers\\nskipped in round-robin\nend\n\ncms -&gt; lh : checkBlacklist()\nloop every blacklisted consumer\n  cms -&gt; cms : probe http://host:port/health\n  alt health check passes\n    cms -&gt; lh : removeFromBlacklist(consumer)\n    note right: consumer re-admitted to rotation\n  else still down\n    cms -&gt; lh : keep blacklisted\n  end\nend\n@enduml\n</code></pre>"},{"location":"components/consumer/#consumer-deregistration","title":"Consumer Deregistration","text":"<pre><code>@startuml\n!theme plain\nskinparam backgroundColor #FAFAFA\nskinparam sequenceMessageAlign center\n\ntitle \"Consumer Deregistration\"\n\nactor \"Consumer App\" as cons\nparticipant \"QueueController\" as qc\nparticipant \"BigQueueManager\" as bqm\nparticipant \"ListenerHolder\" as lh\ndatabase \"etcd\" as etcd\n\ncons -&gt; qc : DELETE /api/queue/subscribe/{queue}\\nBody: {host, port}\nqc -&gt; bqm : deregisterListener(queue, host, port)\nbqm -&gt; lh : removeConsumer(host, port)\nbqm -&gt; etcd : deregister consumer\n\nalt No consumers left\n  bqm -&gt; bqm : cancelScheduler()\\n(stop draining \u2014 no one to deliver to)\n  note right: messages remain in BigQueue\\nuntil a consumer registers\nend\n\nqc --&gt; cons : 200 OK\n@enduml\n</code></pre>"},{"location":"components/consumer/#webclient-pool-configuration","title":"WebClient Pool Configuration","text":"Parameter Value Purpose <code>maxConnections</code> <code>max(tps, 2000)</code> Concurrent HTTP connections <code>pendingAcquire</code> <code>tps \u00d7 10</code> Queued pending connection requests <code>maxIdleTime</code> <code>30 s</code> Idle connection eviction <code>maxLifeTime</code> <code>60 s</code> Maximum connection age <code>connectTimeout</code> <code>4 s</code> TCP connect timeout <code>responseTimeout</code> <code>10 s</code> HTTP response timeout <code>writeTimeout</code> <code>5 s</code> Request write timeout <code>keepAlive</code> <code>true</code> TCP keepalive for dead connection detection"},{"location":"components/managed-ledger/","title":"Managed Ledger","text":"<p>The Managed Ledger is the broker's durability engine. It wraps Apache BookKeeper's raw ledger API with lifecycle management, automatic rotation, and timeout protection.</p> <p>The implementation in <code>ManagedLedgerImpl</code> is closely modelled on the Apache Pulsar managed ledger for proven correctness in distributed environments.</p>"},{"location":"components/managed-ledger/#architecture","title":"Architecture","text":"<pre><code>@startuml\n!theme plain\nskinparam backgroundColor #FAFAFA\nskinparam defaultFontName Inter\n\npackage \"RecordLedger\" {\n  class RecordLedger {\n    - ledgers: Map&lt;String, ManagedLedger&gt;\n    - config: ManagedLedgerConfig\n    + writeAheadLog(entry, action): Mono&lt;Void&gt;\n    + onLedgerCreated(queue, ledgerId)\n    + onLedgerClosed(ledgerId)\n  }\n}\n\npackage \"ledger/\" {\n  interface ManagedLedger {\n    + asyncAddEntry(data, callback): void\n    + close(): void\n    + getName(): String\n  }\n\n  class ManagedLedgerImpl {\n    - state: LedgerState (volatile)\n    - currentLedger: LedgerHandle\n    - ledgerId: long\n    - currentLedgerEntries: long\n    - pendingAddEntries: ConcurrentLinkedQueue\n    - executor: OrderedExecutor\n    - config: ManagedLedgerConfig\n    + asyncAddEntry(data, callback): void\n    - createLedger(): void\n    - rotateLedger(): void\n    - checkAndCompleteLedgerOpTask(): void\n  }\n\n  class AddEntryOperation {\n    + data: ByteBuf\n    + callback: AddEntryCallback\n    + startTime: long\n    + timeoutTask: Timeout\n  }\n\n  interface AddEntryCallback {\n    + addComplete(position, ctx): void\n    + addFailed(exception, ctx): void\n  }\n\n  class Position {\n    + ledgerId: long\n    + entryId: long\n  }\n\n  class ManagedLedgerConfig {\n    + ensembleSize: int = 1\n    + writeQuorum: int = 1\n    + ackQuorum: int = 1\n    + maxEntriesPerLedger: long\n    + maxLedgerSizeInBytes: long\n    + maxLedgerRolloverTimeSeconds: int\n    + metadataOperationsTimeoutSeconds: int = 30\n  }\n\n  ManagedLedger &lt;|.. ManagedLedgerImpl\n  ManagedLedgerImpl --&gt; AddEntryOperation : pending queue\n  ManagedLedgerImpl --&gt; ManagedLedgerConfig\n  AddEntryOperation --&gt; AddEntryCallback\n  ManagedLedgerImpl --&gt; Position : returns on success\n}\n\nRecordLedger --&gt; ManagedLedger : one per queue\n@enduml\n</code></pre>"},{"location":"components/managed-ledger/#ledger-lifecycle-rotation","title":"Ledger Lifecycle &amp; Rotation","text":"<pre><code>@startuml\n!theme plain\nskinparam backgroundColor #FAFAFA\nskinparam sequenceMessageAlign center\n\ntitle \"Ledger Creation and Rotation\"\n\nparticipant \"ManagedLedgerImpl\" as mli\nparticipant \"BookKeeper Client\" as bkc\ndatabase \"BookKeeper\" as bk\nparticipant \"RecordLedger\\nListener\" as listener\n\nnote over mli : state = None\n\nmli -&gt; mli : asyncAddEntry() called first time\nmli -&gt; mli : state = CreatingLedger\nmli -&gt; bkc : createLedger(ensemble, write, ack, password)\nbkc -&gt; bk : create ledger\nbk --&gt; bkc : LedgerHandle (ledgerId)\nbkc --&gt; mli : LedgerHandle\nmli -&gt; mli : state = LedgerOpened\nmli -&gt; listener : onLedgerCreated(name, ledgerId)\nmli -&gt; mli : drain pendingAddEntries queue\n\nloop normal writes\n  mli -&gt; bkc : lh.asyncAddEntry(data, cb)\n  mli -&gt; mli : currentLedgerEntries++\nend\n\nnote over mli : rotation check after each write\n\nalt Max entries reached\n  mli -&gt; mli : state = ClosingLedger\n  mli -&gt; bkc : lh.asyncClose()\n  bkc --&gt; mli : closed\n  mli -&gt; listener : onLedgerClosed(ledgerId)\n  mli -&gt; mli : createLedger() [new ledger]\nend\n@enduml\n</code></pre>"},{"location":"components/managed-ledger/#rotation-triggers","title":"Rotation Triggers","text":"Condition Check Entry count <code>currentLedgerEntries &gt;= maxEntriesPerLedger</code> Ledger size <code>lh.getLength() &gt;= maxLedgerSizeInBytes</code> Time-based <code>age &gt;= maxLedgerRolloverTimeSeconds</code>"},{"location":"components/managed-ledger/#pending-entry-queue","title":"Pending Entry Queue","text":"<p>When a write arrives while the ledger is in <code>CreatingLedger</code> state (rotation in progress), the entry is queued and replayed immediately after the new ledger opens:</p> <pre><code>@startuml\n!theme plain\nskinparam backgroundColor #FAFAFA\n\ntitle \"Pending Entry Queue During Rotation\"\n\n|ManagedLedgerImpl|\nstart\n\n:asyncAddEntry() arrives;\n\nif (state == LedgerOpened?) then (yes)\n  :Write directly to BookKeeper;\nelse if (state == CreatingLedger?) then (yes)\n  :Add to pendingAddEntries queue;\n  note: replayed when state \u2192 LedgerOpened\nelse (other)\n  :Fail with ManagedLedgerException;\nendif\n\nstop\n@enduml\n</code></pre>"},{"location":"components/managed-ledger/#timeout-protection","title":"Timeout Protection","text":"<p>Every <code>AddEntryOperation</code> has a Netty <code>Timeout</code> that fires if the BookKeeper write does not complete within <code>metadataOperationsTimeoutSeconds</code> (default 30 s):</p> <pre><code>@startuml\n!theme plain\nskinparam backgroundColor #FAFAFA\nskinparam sequenceMessageAlign center\n\ntitle \"Write Timeout Handling\"\n\nparticipant \"ManagedLedgerImpl\" as mli\nparticipant \"HashedWheelTimer\" as hwt\nparticipant \"BookKeeper\" as bk\nparticipant \"RecordLedger\" as rl\n\nmli -&gt; hwt : schedule timeout (30 s)\nmli -&gt; bk : asyncAddEntry(data, callback)\n\nalt BK responds within 30 s\n  bk --&gt; mli : AddCallback.addComplete()\n  mli -&gt; hwt : cancel timeout\n  mli --&gt; rl : callback.addComplete(position)\nelse Timeout fires\n  hwt -&gt; mli : onTimeout()\n  mli -&gt; mli : state = WriteFailed\n  mli --&gt; rl : callback.addFailed(TimeoutException)\n  rl -&gt; rl : SQL fallback path\nend\n@enduml\n</code></pre>"},{"location":"components/managed-ledger/#pulsar-alignment","title":"Pulsar Alignment","text":"<p><code>ManagedLedgerImpl</code> deliberately mirrors the Apache Pulsar implementation to benefit from its proven correctness:</p> Aspect Pulsar This Broker State machine 9 states Identical 7-state subset Executor <code>OrderedExecutor</code> from BK worker pool Same Pending entry queue <code>ConcurrentLinkedQueue</code> Same Timeout 30 s <code>HashedWheelTimer</code> Same Race condition guard <code>checkAndCompleteLedgerOpTask()</code> Same Rotation logic Entry count + size + time Same <p>See <code>docs/PULSAR_COMPARISON.md</code> for a detailed side-by-side comparison.</p>"},{"location":"components/monitoring/","title":"Monitoring &amp; Metrics","text":"<p>The broker exposes rich operational metrics via Micrometer + Prometheus and provides health monitoring through scheduled internal services.</p>"},{"location":"components/monitoring/#monitoring-architecture","title":"Monitoring Architecture","text":"<pre><code>@startuml\n!theme plain\nskinparam backgroundColor #FAFAFA\nskinparam defaultFontName Inter\n\npackage \"Monitoring Layer\" {\n  class QueueMonitorService {\n    - monitorQueues() @Scheduled(5s)\n    - bufferRecovery() @Scheduled(1s)\n    - collectPendingLedgerStats() @Scheduled(5s)\n  }\n\n  class ConsumerMonitorService {\n    - trackDelivery(queue, consumer, success)\n    - checkBlacklists()\n    - probeConsumerHealth()\n  }\n\n  class QueueFailoverService {\n    - initiateFailover(queue, failedConsumer)\n    - rebalanceTPS(queue)\n  }\n\n  class LocalStatisticService {\n    + recordEnqueue(queue)\n    + recordDequeue(queue)\n    + recordInFlight(queue, delta)\n    + recordConsumerError(queue)\n    + getStats(queue): LocalQueueStatistic\n  }\n\n  class AggrigatedStatisticService {\n    - cache: Map&lt;String, AggrigatedQueueStatistic&gt;\n    + aggregateAcrossNodes(): Map&lt;String, AggStats&gt;\n    + pendingLedgerCount(queue): long\n  }\n}\n\ndatabase \"Prometheus\\n/actuator/prometheus\" as prom\ndatabase \"Micrometer\\nRegistry\" as micro\n\nQueueMonitorService --&gt; LocalStatisticService\nQueueMonitorService --&gt; AggrigatedStatisticService\nConsumerMonitorService --&gt; LocalStatisticService\nLocalStatisticService --&gt; micro\nmicro --&gt; prom\n@enduml\n</code></pre>"},{"location":"components/monitoring/#scheduled-monitor-tasks","title":"Scheduled Monitor Tasks","text":""},{"location":"components/monitoring/#queuemonitorservice","title":"<code>QueueMonitorService</code>","text":"<pre><code>@startuml\n!theme plain\nskinparam backgroundColor #FAFAFA\n\ntitle \"QueueMonitorService Scheduled Tasks\"\n\n|monitorQueues \u2014 every 5 s|\nstart\n:List all active queues;\nrepeat\n  :Check consumer health;\n  if (Consumer blacklisted?) then (yes)\n    :ConsumerMonitorService.probe();\n    if (Consumer recovered?) then (yes)\n      :Remove from blacklist;\n    endif\n  endif\n  :Check queue size;\n  if (Messages pending + consumer available?) then (yes)\n    :Trigger drain scheduler;\n  endif\n  :Rebalance TPS across pods;\nrepeat while (more queues?)\nstop\n\n|bufferRecovery \u2014 every 1 s|\nstart\n:Scan all nodes via AggrigatedStatisticService;\n:Identify queues with pending\\nledger entries;\n:Trigger RecoveryService.recover(queue);\nstop\n\n|collectPendingLedgerStats \u2014 every 5 s|\nstart\n:Query LedgerTrackingRegistry;\n:Cache unprocessed ledger counts;\n:Update AggrigatedQueueStatistic;\nstop\n@enduml\n</code></pre>"},{"location":"components/monitoring/#micrometer-metrics-reference","title":"Micrometer Metrics Reference","text":""},{"location":"components/monitoring/#publish-metrics","title":"Publish Metrics","text":"Metric Type Description <code>queue.publish.total</code> Counter Total publish operations (per queue tag) <code>queue.publish.errors</code> Counter Failed publishes <code>queue.publish.rtt</code> Timer Publish round-trip (success / locked / retriable)"},{"location":"components/monitoring/#wal-ledger-metrics","title":"WAL (Ledger) Metrics","text":"Metric Type Description <code>queue.consume.ledger.submit</code> Counter WAL entries submitted to BookKeeper <code>queue.consume.ledger.ack</code> Counter WAL entries successfully acknowledged <code>queue.consume.ledger.nack</code> Counter WAL entries that failed (SQL fallback triggered) <code>ledger.creation.success</code> Counter Managed ledger instances created <code>ledger.entry.submit</code> Counter asyncAddEntry calls <code>ledger.entry.ack</code> Counter addComplete callbacks <code>ledger.sql.fallback</code> Counter Times SQL fallback was invoked"},{"location":"components/monitoring/#consumer-delivery-metrics","title":"Consumer Delivery Metrics","text":"Metric Type Description <code>queue.consumer.total</code> Counter Successful consumer deliveries <code>queue.consumer.errors</code> Counter Failed consumer deliveries"},{"location":"components/monitoring/#queue-operation-metrics","title":"Queue Operation Metrics","text":"Metric Type Description <code>queue.{name}.enqueue</code> Counter BigQueue enqueue operations <code>queue.{name}.dequeue</code> Counter BigQueue dequeue operations"},{"location":"components/monitoring/#metrics-flow","title":"Metrics Flow","text":"<pre><code>@startuml\n!theme plain\nskinparam backgroundColor #FAFAFA\nskinparam sequenceMessageAlign center\n\ntitle \"Metrics Collection Flow\"\n\nparticipant \"BigQueueManager\" as bqm\nparticipant \"RecordLedger\" as rl\nparticipant \"LocalStatisticService\" as lss\nparticipant \"Micrometer\\nCounter/Timer\" as mc\ndatabase \"Prometheus\\nScrape /actuator/prometheus\" as prom\nparticipant \"Grafana\" as grafana\n\nbqm -&gt; lss : recordEnqueue(queue)\nlss -&gt; mc : counter(\"queue.publish.total\", queue).increment()\n\nrl -&gt; mc : counter(\"ledger.entry.ack\").increment()\n\nnote over mc : Micrometer aggregates\\nall counters in memory\n\nprom -&gt; mc : GET /actuator/prometheus (scrape every 15s)\nmc --&gt; prom : text/plain Prometheus format\n\nprom -&gt; grafana : Prometheus datasource\ngrafana -&gt; grafana : render dashboards\n@enduml\n</code></pre>"},{"location":"components/monitoring/#actuator-endpoints","title":"Actuator Endpoints","text":"Endpoint Port Description <code>/actuator/prometheus</code> <code>1571</code> Prometheus metrics scrape <code>/actuator/health</code> <code>1571</code> Spring Boot health check <code>/actuator/admin/queue/{name}</code> <code>1571</code> Per-queue statistics (JSON) <code>/api/node</code> <code>1771</code> List active broker nodes <code>/api/ledger?queue=X</code> <code>1771</code> Query ledger records for queue"},{"location":"components/monitoring/#queue-detail-statistics-admin-api","title":"Queue Detail Statistics (Admin API)","text":"<p><code>GET /actuator/admin/queue/{name}</code> returns a <code>AggrigatedQueueStatistic</code> JSON:</p> <pre><code>{\n  \"queueName\": \"orders\",\n  \"localEnqueue\": 15000,\n  \"localDequeue\": 14950,\n  \"inFlight\": 12,\n  \"consumerErrors\": 3,\n  \"pendingLedgerEntries\": 0,\n  \"activeConsumers\": 2,\n  \"configuredTPS\": 500,\n  \"effectiveLocalTPS\": 167\n}\n</code></pre>"},{"location":"components/monitoring/#recommended-grafana-panels","title":"Recommended Grafana Panels","text":"<pre><code>@startuml\n!theme plain\nskinparam backgroundColor #FAFAFA\n\ntitle \"Suggested Grafana Dashboard Layout\"\n\nrectangle \"Broker Overview\" {\n  rectangle \"Publish Rate\\n(queue.publish.total / 1m)\" as pr\n  rectangle \"Consumer Delivery Rate\\n(queue.consumer.total / 1m)\" as dr\n  rectangle \"Consumer Error Rate\\n(queue.consumer.errors / 1m)\" as er\n  rectangle \"WAL Ack Rate\\n(ledger.entry.ack / 1m)\" as wr\n}\n\nrectangle \"Queue Health\" {\n  rectangle \"Queue Depth\\n(queue.*.enqueue - queue.*.dequeue)\" as qd\n  rectangle \"In-Flight Messages\\n(per queue)\" as inf\n  rectangle \"Pending Ledger Entries\\n(recovery backlog)\" as ple\n}\n\nrectangle \"WAL Health\" {\n  rectangle \"SQL Fallback Rate\\n(ledger.sql.fallback / 1m)\" as sfr\n  rectangle \"Ledger Rotation Rate\\n(ledger.creation.success / 1m)\" as lrr\n}\n@enduml\n</code></pre>"},{"location":"components/queue-manager/","title":"Queue Manager","text":"<p>The queue manager layer is the core of the broker. It coordinates message ingestion, buffering, scheduling, and delivery.</p>"},{"location":"components/queue-manager/#class-hierarchy","title":"Class Hierarchy","text":"<pre><code>@startuml\n!theme plain\nskinparam backgroundColor #FAFAFA\nskinparam defaultFontName Inter\n\ninterface QueueManager {\n  + publish(queue, message, tps): Mono&lt;Void&gt;\n  + consume(queue): Flux&lt;Message&gt;\n  + registerListener(queue, host, port, tps)\n  + deregisterListener(queue, host, port)\n  + size(queue): long\n  + inFlight(queue): int\n}\n\nclass BigQueueManager {\n  - containers: Map&lt;String, QueueContainer&gt;\n  - listeners: Map&lt;String, ListenerHolder&gt;\n  - recordLedger: RecordLedger\n  - reactiveHandler: ReactiveMessageHandler\n  - rateLimiter: RedisGlobalRateLimiter\n  + publishtoPipe(queue, message, tps): Mono&lt;Void&gt;\n  + handleMessage(bytes, consumer): Mono&lt;DeliveryAck&gt;\n  + tryCreateQueue(queue): QueueHolder\n  + requestQueueDeletion(queue): Mono&lt;Void&gt;\n}\n\nclass QueueContainer {\n  - holders: ConcurrentHashMap&lt;String, QueueHolder&gt;\n  + getQueueOrCreateIfNotExist(queue): QueueHolder\n  + removeQueue(queue): void\n}\n\nclass QueueHolder {\n  - queue: BigQueueImpl\n  - rateLimiter: RateLimiter\n  - scheduler: ScheduledFuture&lt;?&gt;\n  - inFlightCount: AtomicInteger\n  - tps: int\n  + enqueue(bytes): void\n  + pipe(bytes): boolean\n  + dequeue(): byte[]\n  + size(): long\n  + inFlight(): int\n  + createScheduleIfNotExist(): void\n  + cancelSchedule(): void\n}\n\nclass ListenerHolder {\n  - consumers: CopyOnWriteArrayList&lt;NamedConsumer&gt;\n  - blacklist: Set&lt;String&gt;\n  - rrIndex: AtomicInteger\n  + addConsumer(host, port): void\n  + removeConsumer(host, port): void\n  + selectConsumer(): Optional&lt;NamedConsumer&gt;\n  + blacklist(consumer): void\n  + isBlacklisted(consumer): boolean\n}\n\nclass NamedConsumer {\n  + host: String\n  + port: int\n  + tps: int\n  + failureCount: AtomicInteger\n  + lastFailure: Instant\n}\n\nQueueManager &lt;|.. BigQueueManager\nBigQueueManager --&gt; QueueContainer\nBigQueueManager --&gt; ListenerHolder\nQueueContainer --&gt; QueueHolder\nListenerHolder --&gt; NamedConsumer\n@enduml\n</code></pre>"},{"location":"components/queue-manager/#bigqueuemanager-core-logic","title":"BigQueueManager \u2014 Core Logic","text":"<p><code>BigQueueManager</code> is the central orchestrator. All publish and consume operations pass through it.</p>"},{"location":"components/queue-manager/#publishtopipe-publish-with-pass-through","title":"<code>publishtoPipe()</code> \u2014 Publish with Pass-Through","text":"<pre><code>@startuml\n!theme plain\nskinparam backgroundColor #FAFAFA\nskinparam sequenceMessageAlign center\n\ntitle \"publishtoPipe() \u2014 With Pass-Through Decision\"\n\nparticipant \"BigQueueManager\" as bqm\nparticipant \"QueueContainer\" as qcon\nparticipant \"QueueHolder\" as qh\nparticipant \"ListenerHolder\" as lh\nparticipant \"RedisGlobalRateLimiter\" as rrl\nparticipant \"RecordLedger\" as rl\nparticipant \"ReactiveMessageHandler\" as rmh\n\n[-&gt; bqm : publishtoPipe(queue, message, tps)\n\nbqm -&gt; qcon : getQueueOrCreateIfNotExist(queue)\nqcon --&gt; bqm : QueueHolder\n\nbqm -&gt; lh : selectConsumer()\n\nalt No consumer\n  bqm -&gt; qh : enqueue(message)\n  bqm -&gt;&gt; rl : writeAheadLog(PUBLISH) [async]\nelse Consumer available\n  bqm -&gt; rrl : tryConsume(queue, 1)\n  alt Rate limit OK\n    bqm -&gt; qh : inFlight()\n    alt In-flight &lt; threshold\n      bqm -&gt; rmh : deliver(message, consumer) [pass-through]\n      bqm -&gt;&gt; rl : writeAheadLog(PUBLISH) [async]\n    else In-flight exceeded\n      bqm -&gt; qh : enqueue(message)\n      bqm -&gt;&gt; rl : writeAheadLog(PUBLISH) [async]\n    end\n  else Rate limit exceeded\n    bqm -&gt; qh : enqueue(message)\n    bqm -&gt;&gt; rl : writeAheadLog(PUBLISH) [async]\n  end\nend\n@enduml\n</code></pre>"},{"location":"components/queue-manager/#queueholder-per-queue-state-machine","title":"QueueHolder \u2014 Per-Queue State Machine","text":"<p><code>QueueHolder</code> manages all state for a single queue on a single pod. It owns:</p> <ul> <li>The <code>BigQueueImpl</code> on disk</li> <li>The Guava <code>RateLimiter</code> for local TPS enforcement</li> <li>The <code>ScheduledFuture</code> that periodically drains the queue</li> <li>An <code>AtomicInteger</code> tracking in-flight message count</li> </ul> <pre><code>@startuml\n!theme plain\nskinparam backgroundColor #FAFAFA\n\ntitle \"QueueHolder Internal State\"\n\nstate \"Idle\\n(empty queue)\" as idle\nstate \"Draining\\n(scheduler active)\" as draining\nstate \"Throttled\\n(rate limit hit)\" as throttled\nstate \"Paused\\n(no consumers)\" as paused\n\n[*] --&gt; idle : created\nidle --&gt; draining : message enqueued\\n+ consumer available\ndraining --&gt; idle : queue empty\ndraining --&gt; throttled : rate limit exceeded\\n(Guava RateLimiter)\nthrottled --&gt; draining : token refilled\ndraining --&gt; paused : all consumers\\nblacklisted / gone\npaused --&gt; draining : consumer re-registered\n@enduml\n</code></pre>"},{"location":"components/queue-manager/#drain-scheduler","title":"Drain Scheduler","text":"<p>The scheduler is created lazily when the first message arrives (if no pass-through was possible). It polls BigQueue at a rate adapted to the queue's configured TPS:</p> <pre><code>pollInterval = max(1, 1000 / tps)  // milliseconds\n</code></pre>"},{"location":"components/queue-manager/#listenerholder-consumer-round-robin","title":"ListenerHolder \u2014 Consumer Round-Robin","text":"<pre><code>@startuml\n!theme plain\nskinparam backgroundColor #FAFAFA\nskinparam sequenceMessageAlign center\n\ntitle \"Round-Robin Consumer Selection\"\n\nparticipant \"ListenerHolder\" as lh\nparticipant \"NamedConsumer[0]\\nhost-a:8080\" as c0\nparticipant \"NamedConsumer[1]\\nhost-b:8080\" as c1\nparticipant \"NamedConsumer[2]\\nhost-c:8080\" as c2\n\nnote over c2 : blacklisted (3 failures)\n\n[-&gt; lh : selectConsumer()\nlh -&gt; lh : rrIndex++ % activeConsumers.size()\n\nalt index=0\n  lh --&gt; c0 : selected\nelse index=1\n  lh --&gt; c1 : selected\nelse index=2 (blacklisted)\n  lh -&gt; lh : skip, try next\n  lh --&gt; c0 : fallback to next valid\nend\n@enduml\n</code></pre> <p>Blacklisting rules:</p> Condition Action 3+ consecutive delivery failures Consumer added to blacklist Consumer deregisters Consumer removed from active list Blacklist TTL expires (5 min) Consumer re-admitted"},{"location":"components/queue-manager/#queuecontainer-lazy-initialization","title":"QueueContainer \u2014 Lazy Initialization","text":"<p><code>QueueContainer</code> creates <code>QueueHolder</code> instances on demand. Before creating a new queue, it checks for residual state from a previous pod instance and cleans it up.</p> <pre><code>@startuml\n!theme plain\nskinparam backgroundColor #FAFAFA\nskinparam sequenceMessageAlign center\n\ntitle \"getQueueOrCreateIfNotExist()\"\n\nparticipant \"QueueContainer\" as qcon\nparticipant \"QueueInstanceTrackingRegistry\\n(etcd)\" as qitr\ndatabase \"BigQueue Files\" as bqf\n\n[-&gt; qcon : getQueueOrCreateIfNotExist(queue)\nqcon -&gt; qcon : check holders map\n\nalt Already exists\n  qcon --&gt; [: return existing QueueHolder\nelse New queue\n  qcon -&gt; qitr : checkAndClaimInstance(queue)\n  alt Residual from previous pod\n    qitr --&gt; qcon : residual detected\n    qcon -&gt; bqf : clean up stale files\n    qcon -&gt; qitr : release old instance\n  end\n  qcon -&gt; bqf : initialise BigQueueImpl\n  qcon -&gt; qitr : register new instance\n  qcon --&gt; [: return new QueueHolder\nend\n@enduml\n</code></pre>"},{"location":"components/rate-limiting/","title":"Rate Limiting","text":"<p>The broker enforces per-queue TPS (transactions per second) limits at two levels: local (per pod, Guava <code>RateLimiter</code>) and global (across all pods, Redis + Bucket4j).</p>"},{"location":"components/rate-limiting/#two-tier-rate-limiting","title":"Two-Tier Rate Limiting","text":"<pre><code>@startuml\n!theme plain\nskinparam backgroundColor #FAFAFA\nskinparam defaultFontName Inter\n\ntitle \"Two-Tier Rate Limiting Architecture\"\n\npackage \"Pod A\" {\n  rectangle \"QueueHolder A\\nGuava RateLimiter\\n(local, tps/podCount)\" as rl_a\n}\n\npackage \"Pod B\" {\n  rectangle \"QueueHolder B\\nGuava RateLimiter\\n(local, tps/podCount)\" as rl_b\n}\n\npackage \"Pod C\" {\n  rectangle \"QueueHolder C\\nGuava RateLimiter\\n(local, tps/podCount)\" as rl_c\n}\n\ndatabase \"Redis\\nBucket4j token bucket\\n(global, full TPS)\" as redis\n\nrl_a --&gt; redis : tryConsume(1)\nrl_b --&gt; redis : tryConsume(1)\nrl_c --&gt; redis : tryConsume(1)\n\nnote bottom of redis\n  Global bucket enforces the hard cap.\n  Local limiters add first-line defence\n  without a network hop.\nend note\n@enduml\n</code></pre> Layer Component Scope Storage Local Guava <code>RateLimiter</code> in <code>QueueHolder</code> Per pod, per queue In-memory Global <code>RedisGlobalRateLimiter</code> (Bucket4j) All pods, per queue Redis"},{"location":"components/rate-limiting/#local-rate-limiter-guava","title":"Local Rate Limiter (Guava)","text":"<p>Each <code>QueueHolder</code> owns a <code>RateLimiter</code> seeded with <code>configuredTPS / activePodCount</code>. This provides a fast, lock-free first check without a Redis round-trip:</p> <pre><code>@startuml\n!theme plain\nskinparam backgroundColor #FAFAFA\n\ntitle \"Local Rate Limit Check\"\n\nstart\n\n:message arrives at QueueHolder.pipe();\n\n:localRateLimiter.tryAcquire();\n\nif (token available?) then (yes)\n  :proceed to global check;\nelse (no \u2014 local limit hit)\n  #lightyellow:enqueue to BigQueue\\n(buffer path);\n  stop\nendif\n\nstop\n@enduml\n</code></pre> <p>When the number of active pods changes, <code>QueueMonitorService</code> recomputes the per-pod rate:</p> <pre><code>localTPS = configuredTPS / activePodCount\n</code></pre>"},{"location":"components/rate-limiting/#global-rate-limiter-redis-bucket4j","title":"Global Rate Limiter (Redis + Bucket4j)","text":"<p><code>RedisGlobalRateLimiter</code> uses a token bucket persisted in Redis. All pods consume from the same bucket, ensuring the aggregate TPS never exceeds the queue's configured limit:</p> <pre><code>@startuml\n!theme plain\nskinparam backgroundColor #FAFAFA\nskinparam sequenceMessageAlign center\n\ntitle \"Global Rate Limit Check (Bucket4j + Redis)\"\n\nparticipant \"BigQueueManager\" as bqm\nparticipant \"RedisGlobalRateLimiter\" as rrl\ndatabase \"Redis\\nBucket key: rl:{queue}\" as redis\n\nbqm -&gt; rrl : tryConsume(queueName, 1)\nrrl -&gt; redis : EVALSHA (Lua script)\\n- check tokens remaining\\n- decrement if &gt; 0\\n- return result\n\nalt tokens available\n  redis --&gt; rrl : consumed = true\n  rrl --&gt; bqm : true (pass-through allowed)\nelse bucket empty\n  redis --&gt; rrl : consumed = false\n  rrl --&gt; bqm : false (buffer)\n  bqm -&gt; bqm : enqueue to BigQueue\nend\n@enduml\n</code></pre>"},{"location":"components/rate-limiting/#redis-key-structure","title":"Redis Key Structure","text":"Key Type TTL Description <code>rl:{queueName}</code> String (Bucket state) No expiry Bucket4j token bucket for the queue"},{"location":"components/rate-limiting/#rate-limit-decision-flow","title":"Rate Limit Decision Flow","text":"<pre><code>@startuml\n!theme plain\nskinparam backgroundColor #FAFAFA\n\ntitle \"Full Rate Limit Decision Flow\"\n\nstart\n\n:Publish request arrives;\n\n:Select consumer\\n(ListenerHolder.selectConsumer());\n\nif (Consumer available?) then (no)\n  #lightyellow:Buffer in BigQueue;\n  stop\nendif\n\n:Check local RateLimiter\\n(Guava, no Redis hop);\n\nif (Local limit OK?) then (no)\n  #lightyellow:Buffer in BigQueue;\n  stop\nendif\n\n:Check global RateLimiter\\n(Redis + Bucket4j);\n\nif (Global limit OK?) then (no)\n  #lightyellow:Buffer in BigQueue;\n  stop\nendif\n\n:Check in-flight count\\n(QueueHolder.inFlight());\n\nif (In-flight &lt; threshold?) then (no)\n  #lightyellow:Buffer in BigQueue;\n  stop\nendif\n\n#palegreen:Pass-through delivery to consumer;\nstop\n@enduml\n</code></pre>"},{"location":"components/rate-limiting/#tps-rebalancing-on-pod-change","title":"TPS Rebalancing on Pod Change","text":"<p>When a pod joins or leaves the cluster, <code>QueueMonitorService</code> redistributes TPS:</p> <pre><code>@startuml\n!theme plain\nskinparam backgroundColor #FAFAFA\nskinparam sequenceMessageAlign center\n\ntitle \"TPS Rebalance on Pod Count Change\"\n\nparticipant \"QueueMonitorService\\n(5 s schedule)\" as qms\ndatabase \"etcd\\nNodeRegistry\" as etcd\nparticipant \"QueueHolder\\n(all queues)\" as qh\ndatabase \"Redis\\nBuckets\" as redis\n\nqms -&gt; etcd : listActiveNodes()\netcd --&gt; qms : [pod-a, pod-b, pod-c]  (3 pods)\n\nqms -&gt; qms : for each queue:\\n  newLocalTPS = configuredTPS / 3\nqms -&gt; qh : setRateLimiter(newLocalTPS)\n\nqms -&gt; redis : reconfigure bucket:\\n  refillRate = configuredTPS\nnote right: global bucket always = configuredTPS;\\nonly local limiters rebalance\n\nqms -&gt; qms : log TPS rebalance event\n@enduml\n</code></pre>"},{"location":"operations/configuration/","title":"Configuration Reference","text":"<p>All broker configuration is in <code>src/main/resources/application.yml</code>.</p>"},{"location":"operations/configuration/#core-broker-settings","title":"Core Broker Settings","text":"<pre><code>broker:\n  base:\n    directory: target/queues      # Root path for BigQueue disk files\n  cleanup:\n    enabled: true                 # Enable orphaned connection cleanup\n    stale-connection-threshold-seconds: 300  # Idle connection timeout (s)\n\nbigbro:\n  broker:\n    standalone: false             # true = single-node dev mode\n    recovery:\n      timeout: 2                  # Dequeue timeout during recovery (s)\n\nserver:\n  name: localhost                 # This pod's hostname (used in etcd registration)\n  port: 1771                      # Main API port\n\nmanagement:\n  server:\n    port: 1571                    # Actuator + metrics port\n</code></pre>"},{"location":"operations/configuration/#apache-bookkeeper","title":"Apache BookKeeper","text":"<pre><code>bigbro:\n  broker:\n    keeper:\n      metadataServiceUri: zk://localhost:2181/bookkeeper/ledgers\n      ensembleSize: 1       # Number of bookies to stripe each ledger across\n      writeQuorum: 1        # Number of bookie replicas to write to\n      ackQuorum: 1          # Minimum acks required before confirming write\n</code></pre> <p>Production values</p> <p>For a 3-bookie ensemble: <code>ensembleSize=3, writeQuorum=3, ackQuorum=2</code></p>"},{"location":"operations/configuration/#mariadb-recovery-tables","title":"MariaDB (Recovery Tables)","text":"<pre><code>spring:\n  datasource:\n    url: jdbc:mariadb://localhost:3306/appdb\n    username: appuser\n    password: apppass\n    driver-class-name: org.mariadb.jdbc.Driver\n    hikari:\n      maximum-pool-size: 30\n      minimum-idle: 10\n      connection-timeout: 30000\n      idle-timeout: 600000\n      max-lifetime: 1800000\n      pool-name: HikariPool-Broker\n</code></pre>"},{"location":"operations/configuration/#redis","title":"Redis","text":"<pre><code>spring:\n  redis:\n    host: localhost\n    port: 6379\n    password: \"\"\n    jedis:\n      pool:\n        max-active: 20\n        max-idle: 10\n        min-idle: 2\n</code></pre> <p>Redis is used for: - Global rate limiting (Bucket4j token buckets, key prefix <code>rl:</code>) - Distributed commands (pub/sub topic <code>broker-command</code>) - Queue instance locking (key prefix <code>lock:</code>)</p>"},{"location":"operations/configuration/#thread-pool-executors","title":"Thread Pool Executors","text":"<p>The broker uses 11 named thread pools. Each is configured under <code>executor.*</code>:</p> Executor Name Default Core Default Max Queue Cap Usage <code>storage</code> 4 8 1000 BigQueue disk I/O <code>batchInsert</code> 2 4 500 SQL batch inserts <code>ledger</code> 4 8 1000 BookKeeper ledger ops <code>instance</code> 2 4 500 Queue instance registry <code>message</code> 10 50 10000 Message publish path <code>consumerMonitor</code> 2 4 100 Consumer health checks <code>queueMonitor</code> 2 4 100 Queue monitoring <code>recoveryCounting</code> 2 4 100 Ledger pending count <code>recovery</code> 4 8 1000 Ledger recovery processing <code>queueScheduler</code> 4 8 1000 Queue drain schedulers <code>sqlBuffer</code> 2 4 500 SQL fallback writes <pre><code>executor:\n  message:\n    corePoolSize: 10\n    maxPoolSize: 50\n    queueCapacity: 10000\n    keepAliveSeconds: 60\n  # ... repeat for each executor name\n</code></pre>"},{"location":"operations/configuration/#logging","title":"Logging","text":"<pre><code># logback.xml governs log output.\n# Key loggers:\nlogging:\n  level:\n    com.open.messaging: INFO\n    org.apache.bookkeeper: WARN\n    io.netty: WARN\n</code></pre>"},{"location":"operations/configuration/#helm-values-kubernetes","title":"Helm Values (Kubernetes)","text":"<p>For Kubernetes deployments via the <code>helmchart/</code> directory:</p> <pre><code># helmchart/values.yaml\n\nimage:\n  repository: backstage4j/broker\n  tag: latest\n  pullPolicy: IfNotPresent\n\nreplicaCount: 3\n\nservice:\n  type: ClusterIP\n  apiPort: 1771\n  managementPort: 1571\n\npersistence:\n  enabled: true\n  storageClass: fast-ssd\n  size: 50Gi\n  mountPath: /data/queues\n\nenv:\n  BROKER_BASE_DIR: /data/queues\n  BOOKKEEPER_METADATA_URI: zk://zookeeper:2181/bookkeeper/ledgers\n  REDIS_HOST: redis-master\n  DB_URL: jdbc:mariadb://mariadb:3306/appdb\n\nresources:\n  requests:\n    cpu: 500m\n    memory: 1Gi\n  limits:\n    cpu: 2\n    memory: 4Gi\n\nautoscaling:\n  enabled: true\n  minReplicas: 2\n  maxReplicas: 10\n  targetCPUUtilizationPercentage: 70\n</code></pre>"},{"location":"operations/database-tables/","title":"Database Tables","text":"<p>The broker uses MariaDB for three purposes: WAL fallback, recovery state tracking, and ledger lifecycle management. All tables are created dynamically at runtime.</p>"},{"location":"operations/database-tables/#table-inventory","title":"Table Inventory","text":"<pre><code>@startuml\n!theme plain\nskinparam backgroundColor #FAFAFA\nskinparam defaultFontName Inter\n\npackage \"MariaDB: appdb\" {\n\n  package \"Per-Queue Tables (dynamic)\" {\n    rectangle \"enqueue_{queue}_tbl\\n(one per queue)\" as et\n    rectangle \"dequeue_{queue}_tbl\\n(one per queue)\" as dt\n  }\n\n  package \"Shared Tables\" {\n    rectangle \"broker_ledger_tracking\\n(single table)\" as blt\n  }\n\n  et ..&gt; dt : message_id reconciliation\\n(SET DIFFERENCE = queue state)\n  blt --&gt; et : drives recovery scan\n  blt --&gt; dt : drives recovery scan\n}\n@enduml\n</code></pre>"},{"location":"operations/database-tables/#1-enqueue_queue_tbl","title":"1. <code>enqueue_{queue}_tbl</code>","text":"<p>One table per queue. Stores every enqueue (publish) event extracted from BookKeeper ledgers. This table is the source of truth for \"what was put into the queue.\"</p>"},{"location":"operations/database-tables/#ddl","title":"DDL","text":"<pre><code>CREATE TABLE IF NOT EXISTS enqueue_{queue}_tbl (\n    message_id     VARCHAR(40)  NOT NULL,\n    timestamp      BIGINT       NOT NULL,\n    payload        BLOB,                   -- full message body\n    queue_instance VARCHAR(50)  NOT NULL,\n    queue_partition VARCHAR(50) NOT NULL,\n    ledger_id      BIGINT       NOT NULL,\n    last_modified  TIMESTAMP    NOT NULL\n                   DEFAULT CURRENT_TIMESTAMP\n                   ON UPDATE CURRENT_TIMESTAMP,\n    PRIMARY KEY (message_id, queue_partition),\n    INDEX idx_queue_instance (queue_instance)\n) ENGINE=InnoDB\n  ROW_FORMAT=DYNAMIC\n  PARTITION BY LIST COLUMNS(queue_partition) (\n      PARTITION p_default VALUES IN ('default')\n  );\n</code></pre>"},{"location":"operations/database-tables/#columns","title":"Columns","text":"Column Type Description <code>message_id</code> VARCHAR(40) UUID \u2014 unique per message; part of composite PK <code>timestamp</code> BIGINT Message creation time (epoch milliseconds) <code>payload</code> BLOB Full serialised message body (<code>BigQueueTextMessage</code> protobuf) <code>queue_instance</code> VARCHAR(50) The broker's file UUID for this queue instance; indexed <code>queue_partition</code> VARCHAR(50) Partition identifier; part of composite PK and partition key <code>ledger_id</code> BIGINT BookKeeper ledger ID this message came from <code>last_modified</code> TIMESTAMP Auto-updated on any row change"},{"location":"operations/database-tables/#key-operations","title":"Key Operations","text":"Operation When SQL Pattern INSERT WAL fallback (BookKeeper failure) or ledger scan during recovery <code>INSERT INTO enqueue_{q}_tbl (...) VALUES (...)</code> INSERT IGNORE Retry path \u2014 avoid duplicate key violation <code>INSERT IGNORE INTO ...</code> Batch INSERT Ledger processing \u2014 bulk load entries <code>batchInsert()</code> via JDBC batch SELECT FOR UPDATE SKIP LOCKED Dequeue: claim messages without contention <code>SELECT ... FOR UPDATE SKIP LOCKED LIMIT N</code> DELETE \u2026 RETURNING Atomic dequeue: remove row and return payload in one statement <code>DELETE FROM enqueue_{q}_tbl WHERE message_id IN (...) RETURNING message_id, payload, ...</code> DELETE JOIN Scrub: remove rows that already have a matching dequeue record <code>DELETE e FROM enqueue_{q}_tbl e JOIN dequeue_{q}_tbl d ON e.message_id = d.message_id</code> SELECT COUNT Recovery progress counting <code>SELECT COUNT(*) WHERE queue_instance = ?</code>"},{"location":"operations/database-tables/#role-in-message-lifecycle","title":"Role in Message Lifecycle","text":"<pre><code>@startuml\n!theme plain\nskinparam backgroundColor #FAFAFA\n\ntitle \"enqueue_tbl Role in Message Lifecycle\"\n\nstart\n\n:BookKeeper write (WAL, PUBLISH action);\n\nif (BookKeeper succeeds?) then (yes)\n  :Ledger scan later migrates\\nentry to enqueue_tbl\\n(cheap storage);\nelse (no \u2014 SQL fallback)\n  :Direct INSERT into enqueue_tbl\\n(immediate SQL fallback);\nendif\n\n:Row persists until message is consumed;\n\n:DELETE \u2026 RETURNING\\n(atomic dequeue);\n\n:Row removed \u2014 message delivered;\n\nstop\n@enduml\n</code></pre>"},{"location":"operations/database-tables/#2-dequeue_queue_tbl","title":"2. <code>dequeue_{queue}_tbl</code>","text":"<p>One table per queue. Records every dequeue (consume) event. No <code>payload</code> column \u2014 only the message identifier is needed to track that a message was consumed.</p>"},{"location":"operations/database-tables/#ddl_1","title":"DDL","text":"<pre><code>CREATE TABLE IF NOT EXISTS dequeue_{queue}_tbl (\n    message_id      VARCHAR(40)  NOT NULL,\n    timestamp       BIGINT       NOT NULL,\n    queue_instance  VARCHAR(50)  NOT NULL,\n    queue_partition VARCHAR(50)  NOT NULL,\n    ledger_id       BIGINT       NOT NULL,\n    last_modified   TIMESTAMP    NOT NULL\n                    DEFAULT CURRENT_TIMESTAMP\n                    ON UPDATE CURRENT_TIMESTAMP,\n    PRIMARY KEY (message_id, queue_partition),\n    INDEX idx_queue_instance (queue_instance)\n) ENGINE=InnoDB\n  ROW_FORMAT=DYNAMIC\n  PARTITION BY LIST COLUMNS(queue_partition) (\n      PARTITION p_default VALUES IN ('default')\n  );\n</code></pre>"},{"location":"operations/database-tables/#columns_1","title":"Columns","text":"Column Type Description <code>message_id</code> VARCHAR(40) UUID \u2014 matches <code>enqueue_tbl.message_id</code>; part of composite PK <code>timestamp</code> BIGINT Dequeue time (epoch milliseconds) <code>queue_instance</code> VARCHAR(50) Queue instance file UUID; indexed <code>queue_partition</code> VARCHAR(50) Partition identifier; part of composite PK and partition key <code>ledger_id</code> BIGINT BookKeeper ledger ID of the dequeue WAL entry <code>last_modified</code> TIMESTAMP Auto-updated on any row change <p>No payload column</p> <p>The <code>dequeue_tbl</code> intentionally has no <code>payload</code> column. Storing the message body here would double the storage footprint. The payload is only kept in <code>enqueue_tbl</code> until delivery is confirmed.</p>"},{"location":"operations/database-tables/#key-operations_1","title":"Key Operations","text":"Operation When SQL Pattern INSERT IGNORE WAL fallback (BookKeeper failure) or ledger scan \u2014 record that message was consumed <code>INSERT IGNORE INTO dequeue_{q}_tbl (...) VALUES (...)</code> Batch INSERT Ledger processing \u2014 bulk dequeue event migration <code>batchInsert()</code> DELETE by instance Queue instance cleanup or pod restart <code>DELETE FROM dequeue_{q}_tbl WHERE queue_instance = ?</code> DELETE JOIN Scrub: remove dequeue records that no longer have matching enqueue records <code>DELETE d FROM dequeue_{q}_tbl d JOIN enqueue_{q}_tbl e ON d.message_id = e.message_id</code> SELECT 1 LIMIT 1 Existence check for a partition <code>hasAnyDataInPartition()</code>"},{"location":"operations/database-tables/#reconciliation-with-enqueue-table","title":"Reconciliation with Enqueue Table","text":"<pre><code>@startuml\n!theme plain\nskinparam backgroundColor #FAFAFA\n\ntitle \"Queue State = enqueue_tbl EXCEPT dequeue_tbl\"\n\nrectangle \"enqueue_{queue}_tbl\" as et {\n  card \"msg-A\" as eA\n  card \"msg-B\" as eB\n  card \"msg-C\" as eC\n  card \"msg-D\" as eD\n}\n\nrectangle \"dequeue_{queue}_tbl\" as dt {\n  card \"msg-A\" as dA\n  card \"msg-C\" as dC\n}\n\nrectangle \"Remaining Queue State\\n(undelivered messages)\" as rqs {\n  card \"msg-B\" #palegreen\n  card \"msg-D\" #palegreen\n}\n\neA ..&gt; dA : consumed \u2014 skip\neB --&gt; rqs : not consumed \u2014 recover\neC ..&gt; dC : consumed \u2014 skip\neD --&gt; rqs : not consumed \u2014 recover\n@enduml\n</code></pre>"},{"location":"operations/database-tables/#3-broker_ledger_tracking","title":"3. <code>broker_ledger_tracking</code>","text":"<p>Single shared table across all queues. Tracks every BookKeeper ledger that was created, whether it has been fully processed (entries migrated to <code>enqueue_tbl</code> / <code>dequeue_tbl</code>), and processing statistics.</p>"},{"location":"operations/database-tables/#ddl_2","title":"DDL","text":"<pre><code>CREATE TABLE IF NOT EXISTS broker_ledger_tracking (\n    queue                   VARCHAR(50),\n    queue_partition         VARCHAR(50),\n    file                    CHAR(36),      -- UUID\n    ledger_id               BIGINT,\n    processed               BOOLEAN,\n    message                 TEXT,\n    total_record_processed  BIGINT,\n    total_enqueue_record    BIGINT,\n    total_dequeue_record    BIGINT,\n    time_elapsed            BIGINT,        -- milliseconds\n    PRIMARY KEY (queue_partition, file, ledger_id)\n);\n</code></pre>"},{"location":"operations/database-tables/#columns_2","title":"Columns","text":"Column Type Description <code>queue</code> VARCHAR(50) Queue name (used for filtering) <code>queue_partition</code> VARCHAR(50) Partition; part of composite PK <code>file</code> CHAR(36) Broker instance file UUID; part of composite PK <code>ledger_id</code> BIGINT BookKeeper ledger ID; part of composite PK <code>processed</code> BOOLEAN <code>false</code> = entries not yet migrated to SQL tables; <code>true</code> = done <code>message</code> TEXT Status message or error description <code>total_record_processed</code> BIGINT Count of ledger entries successfully processed <code>total_enqueue_record</code> BIGINT Count of PUBLISH entries found in this ledger <code>total_dequeue_record</code> BIGINT Count of CONSUME entries found in this ledger <code>time_elapsed</code> BIGINT Wall-clock time to process this ledger (ms)"},{"location":"operations/database-tables/#key-operations_2","title":"Key Operations","text":"Operation When SQL Pattern INSERT New ledger created in BookKeeper <code>INSERT INTO broker_ledger_tracking (...) VALUES (...)</code> with <code>processed=false</code> SELECT Lookup ledger state <code>SELECT * ... WHERE queue_partition=? AND file=? AND ledger_id=?</code> SELECT FOR UPDATE SKIP LOCKED Recovery: claim a ledger for processing (prevents duplicate processing on multi-pod) <code>SELECT ... FOR UPDATE SKIP LOCKED</code> SELECT COUNT Count pending (unprocessed) ledgers for a queue <code>SELECT COUNT(*) WHERE queue=? AND processed=0</code> SELECT with NOT IN Find ledgers belonging to old/stale broker instances <code>WHERE file NOT IN (...)</code> UPDATE Mark ledger processed + write stats <code>UPDATE ... SET processed=true, total_record_processed=?, time_elapsed=? WHERE ...</code> UPDATE conditional Only mark processed if not already done (idempotent) <code>UPDATE ... WHERE ... AND (processed IS NULL OR processed=FALSE)</code> DELETE Remove fully processed ledger tracking row <code>DELETE WHERE queue_partition=? AND file=? AND ledger_id=?</code>"},{"location":"operations/database-tables/#role-in-recovery","title":"Role in Recovery","text":"<pre><code>@startuml\n!theme plain\nskinparam backgroundColor #FAFAFA\nskinparam sequenceMessageAlign center\n\ntitle \"broker_ledger_tracking in Recovery Flow\"\n\nparticipant \"RecoveryService\" as rs\ndatabase \"broker_ledger_tracking\" as blt\ndatabase \"Apache BookKeeper\" as bk\ndatabase \"enqueue_{q}_tbl\" as et\ndatabase \"dequeue_{q}_tbl\" as dt\n\nrs -&gt; blt : SELECT WHERE queue=? AND processed=FALSE\\nFOR UPDATE SKIP LOCKED\nblt --&gt; rs : [unprocessed ledger rows]\n\nloop for each unprocessed ledger\n  rs -&gt; bk : open ledger (ledgerId)\n  rs -&gt; bk : readEntries(0, lastAddConfirmed)\n\n  loop for each entry\n    alt WALAction.PUBLISH\n      rs -&gt; et : INSERT INTO enqueue_{q}_tbl (batch)\n    else WALAction.CONSUME\n      rs -&gt; dt : INSERT IGNORE INTO dequeue_{q}_tbl (batch)\n    end\n  end\n\n  rs -&gt; blt : UPDATE SET processed=TRUE,\\ntotal_enqueue_record=N,\\ntotal_dequeue_record=M,\\ntime_elapsed=T\nend\n@enduml\n</code></pre>"},{"location":"operations/database-tables/#table-partitioning","title":"Table Partitioning","text":"<p>Both <code>enqueue_tbl</code> and <code>dequeue_tbl</code> use LIST COLUMNS partitioning on <code>queue_partition</code>:</p> <pre><code>PARTITION BY LIST COLUMNS(queue_partition) (\n    PARTITION p_default VALUES IN ('default')\n);\n</code></pre> <p>New partitions are added dynamically as new queue partitions are created:</p> <pre><code>ALTER TABLE enqueue_{queue}_tbl\n  ADD PARTITION (PARTITION p_{sanitized_id} VALUES IN ('{partition_id}'));\n</code></pre> <p>This limits full-table scans to a single partition when filtering by <code>queue_partition</code>.</p>"},{"location":"operations/database-tables/#table-lifecycle","title":"Table Lifecycle","text":"<pre><code>@startuml\n!theme plain\nskinparam backgroundColor #FAFAFA\n\ntitle \"Table Lifecycle \u2014 Queue Create to Delete\"\n\nstart\n\n:Queue created\\n(QueueContainer.getQueueOrCreateIfNotExist);\n\nfork\n  :CREATE TABLE enqueue_{queue}_tbl;\nfork again\n  :CREATE TABLE dequeue_{queue}_tbl;\nend fork\n\n:INSERT into broker_ledger_tracking\\nwhen first ledger is created;\n\nrepeat\n  :Normal operation;\\n:enqueue rows added on publish,\\ndequeue rows added on consume;\nrepeat while (queue active?)\n\n:DELETE command broadcast\\n(BrokerCommander \u2192 all pods);\n\nfork\n  :DROP TABLE enqueue_{queue}_tbl;\nfork again\n  :DROP TABLE dequeue_{queue}_tbl;\nend fork\n\n:DELETE FROM broker_ledger_tracking\\nWHERE queue=?;\n\nstop\n@enduml\n</code></pre>"},{"location":"operations/deployment/","title":"Deployment","text":""},{"location":"operations/deployment/#docker-single-node","title":"Docker (Single Node)","text":"<p>A <code>Dockerfile</code> and <code>docker-compose.yaml</code> are provided for local development.</p> <pre><code># Build the broker image\ndocker build -f Dockerfile -t backstage4j/broker:latest .\n\n# Start with all dependencies\ndocker-compose up -d\n</code></pre> <p>The <code>docker-compose.yaml</code> starts:</p> <ul> <li><code>broker</code> \u2014 the broker pod</li> <li><code>bookkeeper</code> \u2014 single bookie + ZooKeeper</li> <li><code>redis</code> \u2014 rate limiting and commands</li> <li><code>mariadb</code> \u2014 recovery tables</li> <li><code>etcd</code> \u2014 node registry</li> </ul>"},{"location":"operations/deployment/#kubernetes-helm","title":"Kubernetes (Helm)","text":"<pre><code># Add chart and install\nhelm install broker ./helmchart \\\n  --namespace messaging \\\n  --set replicaCount=3 \\\n  --set persistence.storageClass=fast-ssd \\\n  --set env.BOOKKEEPER_METADATA_URI=zk://zookeeper:2181/bookkeeper/ledgers \\\n  --set env.REDIS_HOST=redis-master \\\n  --set env.DB_URL=jdbc:mariadb://mariadb:3306/appdb\n</code></pre>"},{"location":"operations/deployment/#prerequisites","title":"Prerequisites","text":"Component Minimum Version Notes Java 21 Temurin distribution recommended Apache BookKeeper 4.17 ZooKeeper 3.8+ as metadata store Redis 6.0+ Sentinel or Cluster for HA MariaDB 10.6+ Galera for HA etcd 3.5+ Kubernetes 1.26+ For HPA + PVC support"},{"location":"operations/deployment/#health-checks","title":"Health Checks","text":"<pre><code># Kubernetes probe configuration\nlivenessProbe:\n  httpGet:\n    path: /actuator/health/liveness\n    port: 1571\n  initialDelaySeconds: 30\n  periodSeconds: 10\n\nreadinessProbe:\n  httpGet:\n    path: /actuator/health/readiness\n    port: 1571\n  initialDelaySeconds: 15\n  periodSeconds: 5\n</code></pre> <p>The readiness probe delays traffic until:</p> <ol> <li>BookKeeper connection is established</li> <li>etcd registration is complete</li> <li>Recovery scan completes (pending ledger entries = 0)</li> </ol>"},{"location":"operations/deployment/#rolling-restart","title":"Rolling Restart","text":"<p>The no-shared-nothing design makes rolling restarts safe:</p> <pre><code>@startuml\n!theme plain\nskinparam backgroundColor #FAFAFA\n\ntitle \"Rolling Restart Sequence\"\n\n|Pod A (restarting)|\nstart\n:Receive SIGTERM;\n:Drain in-flight messages\\n(graceful shutdown timeout: 30s);\n:Complete WAL writes;\n:Deregister from etcd;\n:Pod terminates;\n\n|Pod A (restarting again)|\n:Pod starts;\n:RecoveryService scans ledgers;\n:Reconcile enqueue_record vs dequeue_record;\n:Re-enqueue undelivered messages to BigQueue;\n:Register in etcd;\n:Begin accepting traffic;\nstop\n@enduml\n</code></pre> <p>Other pods continue serving during the restart. The restarting pod's queue state is recovered from its own ledger entries and SQL tables.</p>"},{"location":"operations/deployment/#cicd-pipeline","title":"CI/CD Pipeline","text":"<p>GitHub Actions builds and pushes a Docker image on every push to <code>master</code> and on every GitHub Release:</p> <pre><code># .github/workflows/maven.yml (abbreviated)\n- name: Build with Maven\n  run: mvn -B clean package --file pom.xml\n\n- name: Build &amp; Push Docker image\n  run: |\n    docker build -f Dockerfile -t backstage4j/broker:latest .\n    docker push backstage4j/broker:latest\n</code></pre> <p>Tags: - <code>latest</code> \u2014 always the most recent master build - <code>{version}</code> \u2014 pinned to a GitHub Release tag</p>"}]}